<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Clean</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://sunxiaojie99.github.io/"/>
  <updated>2020-06-19T00:47:56.465Z</updated>
  <id>https://sunxiaojie99.github.io/</id>
  
  <author>
    <name>Carol Sun</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Deep Residual Learning for Image Recognition</title>
    <link href="https://sunxiaojie99.github.io/2020/06/17/ResNet/"/>
    <id>https://sunxiaojie99.github.io/2020/06/17/ResNet/</id>
    <published>2020-06-17T07:46:52.000Z</published>
    <updated>2020-06-19T00:47:56.465Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="deep-residual-learning-for-image-recognition">Deep Residual Learning for Image Recognition</span><a href="#deep-residual-learning-for-image-recognition" class="header-anchor">#</a></h1><div class="toc"><!-- toc --><ul><li><a href="#1-introduction-fang-fa-gai-shu">1. Introduction（方法概述）</a><ul><li><a href="#1-1-ti-chu">1.1 提出</a></li><li><a href="#1-2-xiao-guo">1.2 效果</a></li></ul></li><li><a href="#2-xiang-guan-gong-zuo-he-ta-ren-de-dui-bi">2. 相关工作（和他人的对比）</a><ul><li><a href="#2-1-can-chai-biao-shi">2.1 残差表示</a></li><li><a href="#2-2-shortcut-lian-jie">2.2 Shortcut连接</a></li></ul></li><li><a href="#3-deep-residual-learning">3. Deep Residual Learning</a><ul><li><a href="#3-1-deep-residual-learning">3.1 Deep Residual Learning</a></li><li><a href="#3-2-identity-mapping-by-shortcuts">3.2 Identity Mapping by Shortcuts</a></li><li><a href="#3-3-network-architectures"><strong>3.3 Network Architectures</strong></a></li><li><a href="#3-4-implementation"><strong>3.4 Implementation</strong></a></li></ul></li><li><a href="#4-shi-yan-jie-guo">4. 实验结果</a><ul><li><a href="#4-1-imagenet-classification"><strong>4.1 ImageNet Classification</strong></a></li></ul></li></ul><!-- tocstop --><p><strong>新的问题</strong>：当深层网络能够收敛时，<strong>退化</strong>问题（degradation problem）又出现了，即随着网络深度的增加，准确率达到饱和（不足为奇）然后迅速退化。意外的是，这种退化<strong>并不是由过拟合造成的</strong>（过拟合是训练集上好，测试集上不好，这里是训练集上也不好）。如图1所示。</p><p><img src="/2020/06/17/ResNet/1.png" style="zoom:67%;"></p><blockquote><p>Fig.1 20层和56层的“plain”网络在CIFAR-10上的训练错误率（左）和测试错误率（右）。越深的网络在训练和测试上都具有越高的错误率。</p></blockquote><p><strong>提出</strong>：a residual learning framework （一个残差学习框架），能够简化使那些非常深的网络的训练，该框架使得层能<strong>根据其输入</strong>来学习残差函数（ residual functions）而非原始函数（unreferenced functions）。</p><h2><span id="1-introduction-fang-fa-gai-shu">1. Introduction（方法概述）</span><a href="#1-introduction-fang-fa-gai-shu" class="header-anchor">#</a></h2><p>训练准确率<strong>退化</strong>（degradation (of training accuracy)）的出现表明了并非所有的系统都是很容易优化的。</p><p><strong>讨论1</strong>：比较一个浅层的框架和它的深层版本。对于更深的模型，这有一种通过构建的解决方案：<strong>恒等映射</strong>（identity mapping）来构建增加的层，而其它层直接从浅层模型中复制而来。这个构建的解决方案表明了，一个更深的模型不应当产生比它的浅层版本更高的训练错误率。实验表明，我们目前无法找到一个与这种构建的解决方案相当或者更好的方案（或者说无法在可行的时间内实现）。</p><h3><span id="1-1-ti-chu">1.1 提出</span><a href="#1-1-ti-chu" class="header-anchor">#</a></h3><p><strong>提出</strong>：一种<strong>深度残差学习</strong>框架（ a deep residual learning framework）来解决这个退化问题</p><ul><li>明确的让这些层来拟合<strong>残差映射</strong>（residual mapping），而不是让每一个堆叠的层直接来拟合所需的底层映射（desired underlying mapping）</li><li>假设所需的底层映射为 $H(x)$，我们<strong>让堆叠的非线性层来拟合另一个映射</strong>： $F(x)=H(x)−x$。 因此原来的映射转化为： $F(x)+x$。我们推断残差映射比原始映射（unreferenced mapping）更容易优化。</li><li>公式 $F(x)+x$ 可以通过前馈神经网络的 “<strong>shortcut连接</strong>” 来实现(Fig.2)。（<u>shortcut 连接</u>：就是跳过一个或者多个层。）在我们的例子中，<strong>shortcut 连接只是简单的执行恒等映射，再将它们的输出和堆叠层的输出叠加在一起</strong>(Fig.2)。<strong>恒等的 shortcut 连接并不增加额外的参数和计算复杂度</strong>。完整的网络仍然能通过端到端的SGD反向传播进行训练，并且能够简单的通过公共库来实现。</li></ul><p><img src="/2020/06/17/ResNet/2.png" style="zoom:67%;"></p><blockquote><p>Fig.2 残差学习：一个构建块。</p></blockquote><h3><span id="1-2-xiao-guo">1.2 效果</span><a href="#1-2-xiao-guo" class="header-anchor">#</a></h3><p>在ImageNet数据集上进行了综合性的实验来展示这个退化问题并评估了提出的方法。</p><ul><li>1) 我们极深的残差网络是很容易优化的，但是对应的“plain”网络（仅进行层的堆叠的网络）在深度增加时却出现了更高的错误率。</li><li>2) 我们的 deep residual 网络能够轻易的增加层数来提高准确率，并且结果也大大优于以前的网络。</li><li>3) 有非常好的泛化性能，CIFAR-10数据集上也出现了类似的现象，这表明了我们提出的方法的优化难度和效果并不仅仅是对于一个特定数据集而言的。</li></ul><h2><span id="2-xiang-guan-gong-zuo-he-ta-ren-de-dui-bi">2. 相关工作（和他人的对比）</span><a href="#2-xiang-guan-gong-zuo-he-ta-ren-de-dui-bi" class="header-anchor">#</a></h2><h3><span id="2-1-can-chai-biao-shi">2.1 残差表示</span><a href="#2-1-can-chai-biao-shi" class="header-anchor">#</a></h3><ul><li>对于向量量化，<strong>残差向量编码</strong>比原始向量编码更加有效。</li><li>……</li></ul><h3><span id="2-2-shortcut-lian-jie">2.2 Shortcut连接</span><a href="#2-2-shortcut-lian-jie" class="header-anchor">#</a></h3><p>shortcut 连接已经经过了很长的一段实践和理论研究过程。</p><ul><li>训练多层感知器（MLPs）的一个早期实践就是添加一个连接输入和输出的线性层。</li><li>在<a href="https://arxiv.org/abs/1409.4842" target="_blank" rel="noopener">Szegedy2015Going</a> 及 <a href="https://arxiv.org/abs/1409.5185" target="_blank" rel="noopener">Lee2015deeply</a>中，将一些中间层直接与辅助分类器相连接可以解决梯度消失/爆炸问题。</li><li>在 <a href="https://arxiv.org/abs/1409.4842" target="_blank" rel="noopener">Szegedy2015Going</a> 中，一个“<strong>inception</strong>”层由一个 shortcut 分支和一些更深的分支组合而成。</li><li>与此同时，“<strong>highway networks</strong>”将 <strong>shortcut连接</strong> 与门控函数（gating functions）结合起来。这些门（gates）是数据相关并且是有额外参数的，而我们的恒等 shortcuts是<strong>无参数</strong>的。当一个门的 shortcut 是“closed”（接近于0）时，highway网络中的层表示非残差函数。相反的，我们的模型总是学习残差函数；我们的恒等 shortcuts 从不关闭，在学习额外的残差函数时，所有的信息总是通过的。此外，highway网络并不能由增加层的深度（例如， 超过100层）来提高准确率。</li></ul><h2><span id="3-deep-residual-learning">3. Deep Residual Learning</span><a href="#3-deep-residual-learning" class="header-anchor">#</a></h2><h3><span id="3-1-deep-residual-learning">3.1 Deep Residual Learning</span><a href="#3-1-deep-residual-learning" class="header-anchor">#</a></h3><ol><li>我们将 $H(x)$ 看作一个由部分堆叠的层（并不一定是全部的网络）来拟合的底层映射（underlying mapping），其中 $x$ 是这些层的输入。</li><li>假设多个非线性层能够逼近复杂的函数，这就等价于这些层能够逼近复杂的残差函数，例如，$H(x)−x$（假设输入和输出的维度相同）。</li><li>所以我们明确的让这些层来估计一个残差函数：$F(x)=H(x)−x$ 而不是 $H(x)$ 。因此原始函数变成了：$F(x)+x$ 。尽管这两个形式应该都能够逼近所需的函数（正如假设），但是学习的难易程度并不相同。</li></ol><p>这个重新表达的动机是由退化问题这个反常的现象(Fig.1，左)。正如我们在introduction中讨论的，如果增加的层能以恒等映射来构建，一个更深模型的训练错误率不应该比它对应的浅层模型的更大。<strong>退化问题表明了，求解器在通过多个非线性层来估计恒等映射上可能是存在困难的</strong>。而伴随着残差学习的重新表达，如果恒等映射是最优的，那么求解器驱使多个非线性层的权重趋向于零来逼近恒等映射。</p><h3><span id="3-2-identity-mapping-by-shortcuts">3.2 Identity Mapping by Shortcuts</span><a href="#3-2-identity-mapping-by-shortcuts" class="header-anchor">#</a></h3><p>我们在堆叠层上采样残差学习算法。一个构建块如 Fig.2 所示。本文中的构建块定义如下（Eq.1）：</p><p><img src="/2020/06/17/ResNet/2.png" style="zoom:67%;"></p><script type="math/tex; mode=display">y = F(x, \{W_i\})+x</script><blockquote><ul><li>其中 $x$ 和 $y$ 分别表示层的输入和输出。</li><li>函数 $F(x, \{W_i\})$ 代表学到的残差映射（residual mapping ）。Fig.2 中的例子包含两层，$F = W_2 σ(W_1 x)$ ，其中$σ$ 代表 ReLU，为了简化省略了偏置项。</li><li>$F+x$ 操作由一个shortcut 连接和元素级（element-wise）加法来表示。</li><li>在加法之后，再执行一个非线性操作（例如，$σ(y)$，如Fig.2） </li></ul></blockquote><ol><li><p>Eq.1中的 <strong>shortcut连接没有增加额外的参数和计算复杂度</strong>。这不仅是一个很有吸引力的做法，同时在对”plain”网络和残差网络进行比较时也是非常重要的。可以在参数、深度、宽度以及计算成本都相同的基础上对两个网络进行公平的比较（除了可以忽略不计的元素级的加法）。</p></li><li><p>在Eq.1中<strong>，$x$ 和 $F$ 的维度必须相同</strong>。如果不相同（例如, 当改变了输入/输出的通道），我们可以通过shortcut<strong>连接执行一个线性映射 $W_s$ 来匹配两者的维度</strong>（Eq.2）（将 $x$ 变换为和 $F$ 相同维度）：</p><script type="math/tex; mode=display">y=F(x,\{W_i\})+W_sx</script></li><li><p>在Eq.1中同样可以使用方阵 $W_s$。但我们的实验表明，恒等映射（identity mapping）已足够解决退化问题（degradation problem ），并且是经济的，因此 <strong>$W_s$ 只是用来解决维度不匹配的问题</strong>。</p></li><li><p><strong>残差函数 $F$ 的形式是灵活可变的。</strong>本文实验中涉及到的函数 $F$ 是两层或者三层的（可以好几层）（Fig.5），当然更多层也是可行的。但是如果 $F$ 只含有一层，Eq.1就和线性函数：$y=W_1x+x$ 一致，因此并不具有任何优势。</p></li></ol><p><img src="/2020/06/17/ResNet/3.png" style="zoom:80%;"></p><h3><span id="3-3-network-architectures"><strong>3.3 Network Architectures</strong></span><a href="#3-3-network-architectures" class="header-anchor">#</a></h3><p>我们在多个 plain 网络和残差网络上进行了测试，并都观测到了一致的现象。接下来将在ImageNet上对两个模型进行讨论。</p><p><img src="/2020/06/17/ResNet/4.png" alt></p><blockquote><p>Fig.3 对应于ImageNet的网络框架举例。 <strong>左</strong>：VGG-19模型 （196亿个FLOPs）作为参考。<strong>中</strong>：plain网络，含有34个参数层（36 亿个FLOPs）。<strong>右</strong>：残差网络，含有34个参数层（36亿个FLOPs）。虚线表示的shortcuts增加了维度。<strong>Table 1</strong>展示了更多细节和其它变体。</p></blockquote><p><strong>Plain网络</strong></p><p>我们的plain网络结构（Fig.3，中）主要受 VGG网络（Fig.3，左）的启发。<br>卷积层主要为3*3的滤波器，并遵循以下两点要求：</p><ul><li>(i) 输出特征尺寸相同的层含有相同数量的滤波器；</li><li>(ii) 如果特征尺寸减半，则滤波器的数量增加一倍来保证每层的时间复杂度相同。我们直接通过stride 为2的卷积层来进行下采样。在网络的最后是一个全局的 average pooling 层和一个1000 类的包含softmax 的全连接层。加权层的层数为34，如Fig.3(中)所示。</li></ul><p>值得注意的是，我们的模型比VGG网络（Fig.3，左）有更少的滤波器和更低的计算复杂度。我们34层的结构含有36亿个FLOPs（乘-加），而这仅仅只有VGG-19 （196亿个FLOPs）的<strong>18%。</strong></p><p><strong>残差网络 Residual Network</strong></p><p>在以上plain网络的基础上，我们插入shortcut连接(Fig.3，右)，将网络变成了对应的残差版本。</p><ul><li><p>如果输入和输出的维度相同时，可以直接使用<strong>恒等shortcuts</strong> (Eq.1)（Fig.3中的实线部分）。</p></li><li><p>当维度增加时（Fig.3中的虚线部分），考虑两个选项，对于这两个选项，当shortcut跨越两种尺寸的特征图时，均使用stride为2的卷积。</p><ul><li>(A) shortcut仍然使用恒等映射，在增加的维度上使用 0 来填充，这样做不会增加额外的参数</li><li>(B) 使用Eq.2的映射shortcut来使维度保持一致（通过1*1的卷积）。</li></ul></li></ul><p><img src="/2020/06/17/ResNet/5.png" alt></p><p>Table 1 对应于ImageNet的结构框架。括号中为构建块的参数(同样见Fig.5)，数个构建块进行堆叠。下采样由stride为2的conv3_1、conv4_1和conv5_1 来实现。</p><h3><span id="3-4-implementation"><strong>3.4 Implementation</strong></span><a href="#3-4-implementation" class="header-anchor">#</a></h3><ul><li><p><strong>图像增强</strong>：针对ImageNet的网络，在[256,480]中对图像的短边进行随机采样（randomly sampled）来调整图像的大小，以进行比例放大（scale augmentation）。 从一张图像或者它的水平翻转（horizontal flip）图像中随机采样一个224*224的剪裁（crop），每个像素都减去均值。使用[21]中的标准颜色增强。</p></li><li><p><strong>标准化</strong>：我们在每一个卷积层之后，激活层之前均使用batch normalization（BN）【<a href="https://www.cnblogs.com/guoyaohua/p/8724433.html】。" target="_blank" rel="noopener">https://www.cnblogs.com/guoyaohua/p/8724433.html】。</a></p></li><li><p><strong>初始化</strong>：我们根据<a href="https://www.computer.org/csdl/proceedings/iccv/2015/8391/00/8391b026-abs.html" target="_blank" rel="noopener">He2014spatial</a>来初始化权值然后从零开始训练所有plain/残差网络。</p></li><li><p><strong>配置</strong>：使用的mini-batch的尺寸为256。学习率从0.1开始，每当错误率平稳时将学习率除以10，整个模型进行60∗10460∗104次迭代训练。我们将权值衰减设置为0.0001，a 动量为0.9。根据 <a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">Ioffe2015Batch</a>，我们并没有使用Dropout。</p></li><li><p>在测试中，为了进行比较，我们采取标准的<strong>10-crop测试</strong>。</p></li></ul><p>为了达到最佳的结果，我们使用<a href="https://arxiv.org/abs/1409.1556" target="_blank" rel="noopener">Simonyan2014Very</a>及<a href="https://www.computer.org/csdl/proceedings/iccv/2015/8391/00/8391b026-abs.html" target="_blank" rel="noopener">He2014spatial</a>中的全卷积形式，并在多个尺度的结果上取平均分（调整图像的大小使它的短边长度分别为{224,256,384,480,640}）。</p><hr><p><strong>【注：10-crop】</strong>1-crop和10-crop顾名思义就是进行1次和10次裁剪。举个例子输入图像是256*256的，网络训练所需图像是224×224的。1-corp是从256×256图像中间位置裁一个224 × 224的图像进行训练，而10-corp是先从中间裁一个224 × 224的图像，然后从图像左上角开始，横着数224个像素，竖着数224个像素开始裁剪，同样的方法在右上，左下，右下各裁剪一次。就得到了5张224 × 224的图像，镜像以后再做一遍，总共就有10张图片了。</p><hr><h2><span id="4-shi-yan-jie-guo">4. 实验结果</span><a href="#4-shi-yan-jie-guo" class="header-anchor">#</a></h2><hr><p>【注：Top-1错误率和Top-5错误率】</p><p>首先是TOP-5正确率，举个例子，比如你训练好了一个网络，你要用这个网络去进行图片分类任务，那我假设要分类的数目有50类，那么当我进行测试时，我输入一张图片，网络会依次输出这50个类别的概率，当所有图片测试完成后，那么：TOP-5正确率就是说，在测试图片的50个分类概率中，取前面5个最大的分类概率，正确的标签（分类）有没有在里面，就是它是不是这前5个中的一个，如果是，就是分类成功，那么他的TOP-5正确率此时等于：所有测试图片中正确标签在前五个分类概率的个数/所有的测试图片数</p><p>那么，TOP-5错误率就是正确标记的样本数不在前五个概率里面的样本数除以总的样本数</p><p>同理，TOP-1错误率就是正确标记的样本数不是最佳概率的样本数除以总的样本数</p><hr><h3><span id="4-1-imagenet-classification"><strong>4.1 ImageNet Classification</strong></span><a href="#4-1-imagenet-classification" class="header-anchor">#</a></h3><p>本文在1000类的ImageNet2012数据集上对我们的方法进行评估。训练集包含128万张图像，验证集包含5万张图像。我们在10万张测试图像上进行测试，并对<strong>top-1</strong>和<strong>top-5</strong> 的错误率进行评估。</p><p><strong>对于Plain网络</strong>：评估了18层和34层的plain网络。34层的网络如图Fig.3(中)所示。18层的结构很相似，具体细节参见Table 1。</p><ul><li>34层的Plain网络比18层的Plain网络具有更高的验证错误率，为了揭示<strong>退化问题</strong>，根据Fig.4(左)我们可以看出，在整个训练过程中34 层的网络具有更高的训练错误率。</li><li>认为这种优化上的困难不太可能是由梯度消失所造成的。因为这些plain网络的训练使用了BN，这能保证前向传递的信号是具有非零方差的。我们同样验证了在反向传递阶段的梯度由于BN而具有良好的范式，所以在前向和反向阶段的信号不会存在消失的问题。</li><li>事实上34层的plain网络仍然具有不错的准确率(Table 3)，这表明了求解器在某种程度上也是有效的。</li></ul><p><strong>对于残差网络</strong>：对18层和34层的残差网络ResNets进行评估。如Fig.3 (右)所示，ResNets的基本框架和plain网络的基本相同，除了在每一对3*3的滤波器上添加了一个shortcut连接。从Table 2和Fig.4中观测到以下三点：</p><ul><li>与plain网络相反，34层的ResNet比18层ResNet的结果更优(<strong>2.8%</strong>)。这表明了这种设置可以很好的解决退化问题，并且我们可以由增加的深度来提高准确率。</li><li>与对应的plain网络相比，34层的ResNet在top-1 错误率上降低了<strong>3.5%</strong> (Table 2)。这也验证了在极深的网络中残差学习的有效性。</li><li>18层的plain网络和残差网络的准确率很接近 (Table 2)，但是ResNet 的收敛速度要快得多。(Fig.4 右 vs 左)。如果网络“<strong>并不是特别深</strong>” (如18层)，现有的SGD能够很好的对plain网络进行求解，而ResNet能够使优化得到更快的收敛。</li></ul><p><img src="/2020/06/17/ResNet/6.png" alt></p><blockquote><p> Fig.4 在<strong>ImageNet</strong>上进行训练。细曲线为训练错误率，粗曲线为使用中心crop时的验证错误率。左：18和34层的plain网络。右：18 和34层的ResNets。在这个图中，残差网络和对应的plain网络相比并没有增加额外的参数。</p></blockquote><p><img src="/2020/06/17/ResNet/7.png" style="zoom:67%;"></p><blockquote><p>Table 2 ImageNet验证集上的Top-1错误率 (%, 10-crop testing)。这里的ResNets并没有额外增加的参数。Fig.4展示了整个训练过程。</p></blockquote><p><img src="/2020/06/17/ResNet/8.png" style="zoom:67%;"></p><blockquote><p>Table 3 在ImageNet验证集上的错误率 (%, <strong>10-crop</strong> testing)。VGG-16是基于我们测试的网络。ResNet-50/101/152使用了选项B——利用映射来匹配增加的维度。</p></blockquote><p><img src="/2020/06/17/ResNet/9.png" style="zoom:67%;"></p><blockquote><p>Table 4 <strong>单一模型</strong>在ImageNet验证集上的错误率(%)(除了 ++ 是在验证集上的结果)。</p></blockquote><p><img src="/2020/06/17/ResNet/10.png" style="zoom:67%;"></p><blockquote><p>Table 5 <strong>组合模型</strong>在ImageNet测试集上的top-5错误率。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;deep-residual-learning-for-image-recognition&quot;&gt;Deep Residual Learning for Image Recognition&lt;/span&gt;&lt;a href=&quot;#deep-residual-learn
      
    
    </summary>
    
    
    
      <category term="paper" scheme="https://sunxiaojie99.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
    <link href="https://sunxiaojie99.github.io/2020/06/16/vgg/"/>
    <id>https://sunxiaojie99.github.io/2020/06/16/vgg/</id>
    <published>2020-06-15T16:12:52.000Z</published>
    <updated>2020-06-17T08:32:25.012Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="very-deep-convolutional-networks-for-large-scale-image-recognition">Very Deep Convolutional Networks for Large-Scale Image Recognition</span><a href="#very-deep-convolutional-networks-for-large-scale-image-recognition" class="header-anchor">#</a></h1><div class="toc"><!-- toc --><ul><li><a href="#1-introduction">1. INTRODUCTION</a></li><li><a href="#2-convnet-pei-zhi">2. ConvNet 配置</a><ul><li><a href="#2-1-jia-gou">2.1 架构</a></li><li><a href="#pei-zhi">配置</a></li><li><a href="#2-3-tao-lun">2.3 讨论</a></li></ul></li><li><a href="#3-fen-lei-kuang-jia">3 分类框架</a><ul><li><a href="#3-1-training">3.1 Training</a></li><li><a href="#3-2-testing">3.2 Testing</a></li></ul></li><li><a href="#4-classification-shi-yan">4. classification 实验</a><ul><li><a href="#4-1-tu-xiang-dan-chi-du-ping-gu">4.1 （图像）单尺度评估</a></li><li><a href="#4-2-duo-chi-du-ping-gu-multi-scale">4.2 多尺度评估 multi-scale</a></li><li><a href="#4-3-duo-cai-qie-tu-xiang-ping-gu-muti-crop">4.3 多裁切图像评估 muti-crop</a></li><li><a href="#4-4-juan-ji-wang-luo-rong-he-convnet-fusion">4.4 卷积网络融合 Convnet Fusion</a></li></ul></li><li><a href="#5-jie-lun">5. 结论</a></li></ul><!-- tocstop --></div><p>[TOC]</p><p>论文时间：2015年</p><ul><li>研究内容：大规模图像识别任务下卷积网络深度对其预测准确率的影响</li><li>主要贡献：使用具有非常小的（3×3）卷积滤波器（convolution filters）的架构对深度不断递增的网络进行全面评估。</li></ul><p>VGG模型论文探讨并证明了以下观点：</p><ol><li>用多层的卷积层组合配以小尺寸的滤波器（3 <em> 3），能实现大尺寸滤波器的感受野的同时，还能使参数数量更少；（其他模型可能会用11</em>11，stride=4的卷积核）</li><li>加深模型深度可以获得更好的分类结果</li><li>训练期间分阶段降低学习率有助模型收敛；</li><li>在数据增强方面，训练时：随机从rescale后的图中裁出224*224的区域（如果rescale后的图很大，那截取到的只是图中的一部分），接下来后再水平翻转，RGB通道随机变换；测试时候，将模型的全连接改成卷积。</li></ol><a id="more"></a><h2><span id="1-introduction">1. INTRODUCTION</span><a href="#1-introduction" class="header-anchor">#</a></h2><p>本文解决了ConvNet架构设计的一个重要方面——深度。为此，固定（v）了结构中的其他参数，并通过<strong>增加更多的卷积层来稳步增加网络的深度</strong>，这是可行的，因为在所有层中都使用了<strong>非常小的（3×3）卷积滤波器（convolution filters）</strong>。</p><h2><span id="2-convnet-pei-zhi">2. ConvNet 配置</span><a href="#2-convnet-pei-zhi" class="header-anchor">#</a></h2><p>为了衡量ConvNet深度在公平环境中所带来的改进，我们所有的ConvNet层配置都采用相同的原则设计。在本部分中，首先描述ConvNet配置的通用布局（第2.1节），然后详细说明评估中使用的具体配置（第2.2节）。 然后（第2.3节）讨论我们的设计选择，并与现有技术进行比较。</p><h3><span id="2-1-jia-gou">2.1 架构</span><a href="#2-1-jia-gou" class="header-anchor">#</a></h3><p>在训练期间，ConvNets的输入是固定尺寸的224×224 RGB图像。</p><ul><li>预处理：唯一做的预处理是从每个像素中<strong>减去在训练集上计算的RGB均值</strong>。</li><li>图像通过堆叠的卷积层，其中使用了感受野（receptive field）非常小的<strong>卷积核（filters ）：3×3</strong>（这是左/右，上/下，中心点概念可捕获的最小尺寸）。</li><li>在其中一种配置中，我们还使用1×1卷积滤波器，这可以看作是输入通道的线性变换（随后是非线性）。</li><li>卷积<strong>步长 stride</strong> 固定为1个像素；</li><li><strong>卷积层的空间填充</strong>（spatial padding）是指，使得在卷积操作后保留原空间的分辨率（resolution），比如如果使用3×3 卷积核，就填充1个像素。</li><li><strong>空间池化（Spatial pooling ）</strong>是由五个最大池化层完成的，每个池化层前面都会有若干个卷积层（并非所有的卷积层后都使用最大池化层）。 </li><li><strong>Max-pooling 最大池化</strong>是以2×2像素窗口上执行，步幅为2。</li><li>堆叠的卷积层（在不同的体系结构中具有不同的深度）之后是三个<strong>完全连接（FC）层</strong>：前两个具有4096个通道，第三个执行1000类别的ILSVRC分类，因此包含1000个通道（一个 为每个类）。</li><li>最后一层是<strong>soft-max层</strong>。 全连接层的配置在所有网络中都是相同的。</li><li><u>所有隐藏层</u>都配备了<strong>ReLU激活函数</strong>。注意到我们的网络（除了一个网络）都没有包含局部响应归一化层标准化（LRN Local Response Normalisation）。这种标准化不会提升ILSVRC数据集的性能，但会导致内存消耗和计算时间的增加。</li></ul><h3><span id="pei-zhi">配置</span><a href="#pei-zhi" class="header-anchor">#</a></h3><p>本文中评估的ConvNet配置在表1中列出，每列一个。 下面我们将以他们的名字（A-E）来提及。 </p><p>所有的配置都遵循2.1节中提到的通用设计，并且仅在深度上有所不同：从网络A中的11个权重层（weight layers）（8个卷积层和3个全连接层）到网络E中的19个权重层（weight layers）（16个卷积层和3个全连接层）。</p><p>卷积层的宽度（通道 channel 数量）相当小，从第一层的64开始，然后在每个最大池层后增加1倍，直到达到512。</p><p>在表2中，我们报告了每个配置的参数数目。 <u>尽管深度很大，但我们网络的权重数量不会超过那些深度较小、但卷积核和感受野宽度更大的网络</u>。</p><p><img src="/2020/06/16/vgg/1.png" style="zoom:67%;"></p><p>注意到在没有任何标准化层的情况下，使用局部响应标准化（ local response normalisation）（A-LRN网络）在模型A上没有改进。 因此，我们在深层架构（B-E）中不采用标准化层。</p><h3><span id="2-3-tao-lun">2.3 讨论</span><a href="#2-3-tao-lun" class="header-anchor">#</a></h3><p><strong>区别性</strong>：我们 ConvNet配置与 ILSVRC-2012以及 ILSVRC-2013的最佳模型相比有着较大差别。区别于<strong>之前的模型在首层卷积层所使用的较大的感受野</strong>（比如11x11卷积核配合步幅4（Krizhevsky et al., 2012），7x7卷积核配合步幅2（Zeiler &amp; Fergus, 2013; Sermanet et al., 2014）），<strong>我们整体都使用了非常小的3x3卷积核配合步幅1</strong>。</p><p><strong>等效性</strong>：显而易见的是，用两层的3x3卷积层组合（中间不包含池化层）所得到的感受野相当于一层的5x5卷积层的感受野；而三层这样的卷积层组合所得到的感受野相当于一层的7x7卷积核的感受野。</p><p><strong>更强的分辨力</strong>：如果我们用三层3x3的卷积层组合来代替一层7x7卷积层，我们会得到什么呢？首先，我们并入了三个ReLU激活函数，而不是一个，这使决策功能的分辨力更强。 </p><p><strong>更少的参数</strong>：其次，我们减少参数的数量：假设三层3×3卷积层相叠的输入和输出都具有C个通道，则该叠层参数化为 $3×(3^2C^2)=27C^2$ 个权重; 同时，一个7×7 卷积层需要 $7^2C^2=49C^2$  参数，参数量会增加 81％。 这<u>可以被看作是在7×7卷积中实施正规化</u>（regularisation）， <u>迫使他们通过3×3卷积核进行分解</u>（两者之间注入非线性）。</p><p><strong>1×1卷积核</strong>：纳入1×1卷积核（配置C，表1）是一种<u>增加决策函数的非线性而不影响卷积层感受野</u>的方法。 尽管在我们的例子中，1×1卷积本质上是一个线性投影到相同维度的空间上（输入和输出通道的数目是相同的），但激活函数引入了一个额外的非线性。 </p><p><strong>与其他工作的对比</strong>：</p><ol><li>大规模数据集+更深：Ciresan等人以前曾使用过小尺寸的卷积滤波器 （2011年），但他们的网络明显不如我们的深，并且他们没有对大规模ILSVRC数据集进行评估。</li><li>Goodfellow等人（2014）将深度ConvNets（11个权重层）应用于街道号识别任务，并表明增加深度能获得更好的性能。</li><li>GoogLeNet（Szegedy et al.，2014）是ILSVRC-2014分类任务中性能最好的一个入门版本，它的开发与我们的工作无关，但它的基础是非常深的ConvNets（22个加权层）和小卷积滤波器（除3×3外，还使用1×1和5×5卷积）。并且，它们的网络拓扑结构比我们的要复杂，并且在第一层更积极地降低了特征图的空间分辨率，以减少计算量。正如将在4.5节中所显示的那样，我们的模型超过了Szegedy等人的模型（2014年）的单网分类准确性。</li></ol><h2><span id="3-fen-lei-kuang-jia">3 分类框架</span><a href="#3-fen-lei-kuang-jia" class="header-anchor">#</a></h2><p>之前介绍了网络配置的细节。 在本节中，我们将介绍ConvNet训练和评估的分类细节。</p><h3><span id="3-1-training">3.1 Training</span><a href="#3-1-training" class="header-anchor">#</a></h3><p>训练是通过使用<strong>小批量梯度下降</strong>（mini-batch gradient descent）（基于反向传播）的<strong>动量优化多项逻辑回归目标</strong>（optimising the multinomial logistic regression objective with momentum）来实现的。</p><p><strong>具体配置细节：</strong></p><ul><li><p><u>批量大小（batch size）</u>设置为256，<u>动量（momentum）</u>为0.9。 训练通过<u>weight 衰减</u>（L2惩罚系数设置为 $5·10^{-4}$ ）和前两个全连接层（<u>dropout</u>设置为0.5）的dropout正则化来调整。 </p></li><li><p><u>学习率</u>最初设置为 $10^{-2}$ ，然后在验证集精度停止增长时再降低10倍。 总的来说，学习率（learning rate）一共降低了3次，并且在370K个迭代（74代）后停止了学习。 </p></li><li><p>我们推测，尽管与（Krizhevsky et al.，2012）相比，网络的参数数量更多，网络深度也更大，但能用更少的迭代次数来实现收敛，由于：（a）更大深度和更小卷积核所带来的隐式正则化；（b）某些图层的预初始化。</p></li></ul><p><strong>网络权重的初始化</strong>很重要，因为由于深度网络中的梯度不稳定，初始化不好可能会导致学习停滞。 </p><ol><li>为了避免这个问题，我们从训练配置A（表1）开始，这个网络足够浅，可以随机初始化进行训练。 </li><li>然后，当训练更深的体系结构时，我们使用了网络A的权值来初始化了前四个卷积层和最后三个完全连接的层，（中间层随机初始化）。</li><li>我们没有降低预初始化图层的学习速率，允许它们在学习期间改变。 对于随机初始化（如有），我们从具有零均值和 <img src="https://www.zhihu.com/equation?tex=10%5E%7B%E2%88%922%7D" alt="[公式]"> 方差的正态分布采样权重。 偏差初始化为零。 </li></ol><p><strong>图像缩放</strong>：</p><p>为了获得224×224固定大小的 ConvNet输入图像，他们从重新缩放的训练图像中随机裁剪（每个SGD迭代每个图像裁剪一次）。 为了进一步增强训练集，被裁剪的图像经过随机水平翻转和随机RGB颜色偏移处理（Krizhevsky et al.，2012）。 下面将介绍训练图像缩放。</p><p><strong>训练图像尺寸。</strong> 设S是等比例缩放的训练图像的最小边，ConvNet基于这些图像的裁剪作为输入（我们也称S为训练尺度）。 裁剪大小固定为224×224，但原则上S可以取不小于224的任何值：对于S = 224，裁剪图将捕获整幅图像统计数据，完全跨越训练图像的最小边; 对于S&gt;&gt;224，裁剪图将对应于图像的一小部分，包含一个小物体或一个物体部分。</p><p><strong>考虑设定训练尺度S的两种方法</strong>。</p><ol><li>第一种方法是<strong>固定S</strong>，对应于单尺度训练（single-scale training）。 在实验中，评估了以两个固定尺度训练的模型：S = 256和S = 384。给定一个ConvNet配置，我们首先使用S = 256来训练网络。为了<strong>加速</strong>S = 384网络的训练，<u>它被初始化为具有S = 256的预训练权重，并且我们使用较小的学习率初始值为 $10^{-3}$</u> 。</li><li><strong>设定S的第二种方法是多尺度训练 (multi-scale training)</strong>，其中通过从特定范围[Smin，Smax]（我们使用Smin = 256和Smax = 512）随机采样S来单独重新调整每个训练图像。 由于图像中的物体可能具有不同的大小，因此在训练时考虑到这一点是有益的。 这可以看作是通过缩放抖动(scale jittering)来<strong>增强训练集( training set augmentation)</strong>，其中单个模型被训练以识别多种类别的物体。 出于<strong>速度</strong>的原因，<u>我们通过对具有相同配置的单尺度模型的所有层进行微调来训练多尺度模型，并使用固定的S = 384进行预训练</u>。</li></ol><h3><span id="3-2-testing">3.2 Testing</span><a href="#3-2-testing" class="header-anchor">#</a></h3><p>测试时，给定一个训练有素的ConvNet和一个输入图像，它按以下方式分类。</p><ol><li>将其等比例缩放到预定义的最小边，表示为Q（我们也将其称为测试尺度）</li><li>然后，网络以类似于（Sermanet等人，2014）的方式被密集地应用在重新缩放的测试图像上。也就是说，全连接的层首先被转换成卷积层（第一个FC层转为7×7的卷积层，后两个FC层转为1×1 卷积层）。然后将所得的全卷积网络应用于整个（未裁剪的）图像。</li><li>其结果是一个类别得分映射，其类别数等于任务的目标分类数，以及一个可变的空间分辨率，取决于输入图像的大小。</li><li>最后，为了获得固定大小的图像类别分数的向量，类别得分映射会被空间平均（sum-pooled）。</li><li>我们还通过水平翻转(horizontal flipping)图像来增强测试集；对原始图像和翻转图像的softmax分类概率进行平均以获得图像的最终分数。</li></ol><p>使用大量的裁剪图像，可以提高准确性，因为与全卷积网络相比，它可以更精细地对输入图像进行采样。此外，由于卷积边界条件不同，<strong>多裁剪图像评估</strong>与<strong>密集评估</strong>是互补的：</p><ul><li>将ConvNet应用于裁剪图像时，卷积后的特征映射用零填充</li><li>而在密集评估的情况下，同一裁切图像的填充天然地来自于图像的相邻部分（由于卷积和空间池化），这大大增加了整个网络的感受野，因此捕获更多的上下文信息。</li><li>尽管我们认为在实践中增加多裁切图像(multiple crops )的计算时间并不能证明潜在的准确度增加，但我们对于每种尺寸规模（5×5个常规栅格和2种翻转）都使用50个裁切图像来评估我们的网络，总共150个裁切图像(crops)、超过3个尺度(scales)，这与Szegedy等人使用的4种尺度、144个裁切图像相当 （2014）。</li></ul><h2><span id="4-classification-shi-yan">4. classification 实验</span><a href="#4-classification-shi-yan" class="header-anchor">#</a></h2><h3><span id="4-1-tu-xiang-dan-chi-du-ping-gu">4.1 （图像）单尺度评估</span><a href="#4-1-tu-xiang-dan-chi-du-ping-gu" class="header-anchor">#</a></h3><ul><li>首先，我们注意到在没有任何标准化层的情况下，<u>使用局部响应标准化（A-LRN网络）在模型A上没有改进</u>。 因此，我们在深层架构（B-E）中不采用标准化层。</li><li>其次，我们观察到<u>分类错误随着ConvNet深度的增加而减少</u>：从模型A的11层到模型E的19层。</li><li>值得注意的是，尽管深度相同，配置C（其包含三个1×1的转换层），比整个网络全部使用3×3 卷积的配置D更差。这表明<u>虽然额外的非线性确实有帮助（C比B好），但使用感受野范围不少的卷积核（D比C好）捕获空间上下文也很重要</u>。</li><li>当深度达到19层时，<u>我们架构的错误率会饱和</u>，但即使是更深的模型也可能对更大的数据集有所帮助。</li><li>我们还特意以B网络为基准，把每两层3x3卷积替换为一层5×5 卷积核的浅网进行比较（其具有与B网络相同的感受野，见2.3节中解释）。该浅层网络的Top-1误差比B网络（用中心裁切图像）的误差高7％，这证实了<u>带有小型卷积核的深网优于具有更大卷积核的浅网</u>。</li><li>最后，即使在测试时使用单尺度图像，训练时的图像缩放（S∈[256; 512]）比起图像固定最小边（S = 256或S = 384）得到明显更好的结果。 这证实了<u>通过尺度抖动来增强训练集确实有助于捕获多尺度图像统计信息</u>。</li></ul><p><img src="/2020/06/16/vgg/2.png" style="zoom:67%;"></p><h3><span id="4-2-duo-chi-du-ping-gu-multi-scale">4.2 多尺度评估 multi-scale</span><a href="#4-2-duo-chi-du-ping-gu-multi-scale" class="header-anchor">#</a></h3><p>在评估了ConvNet模型的单一尺度后，我们现在<u>评估测试时尺度抖动的影响</u>。</p><p>包括在一个测试图像的多个缩放版本上运行模型（对应于不同的Q值），然后对结果分类的后验概率进行平均。</p><p> 考虑到训练和测试所用尺度的巨大差异会导致性能下降</p><ul><li>用固定S训练的模型在三个图像尺寸上进行测试评估，测试尺寸接近训练尺寸：Q = {S - 32，S，S + 32}。 </li><li>同时，训练时的尺度抖动可使网络在测试时使用更广泛的尺度范围，所以模型用变量 S∈[Smin, Smax] ，在更大范围的尺寸Q = {Smin，0.5(Smin + Smax)，Smax}下评估。</li></ul><p>结论：</p><ul><li>表4中所示的结果表明，<strong>在测试时的尺度抖动可得到更好的性能</strong>（与在单尺度上评估相同模型相比，如表3所示）。</li><li>与以前一样，最深的配置（D和E）表现最好，而使用缩放抖动的训练模型优于使用固定最小边S的训练模型。</li></ul><p><img src="/2020/06/16/vgg/4.png" style="zoom:67%;"></p><h3><span id="4-3-duo-cai-qie-tu-xiang-ping-gu-muti-crop">4.3 多裁切图像评估 muti-crop</span><a href="#4-3-duo-cai-qie-tu-xiang-ping-gu-muti-crop" class="header-anchor">#</a></h3><p>在表5中，我们将密集的（dense）ConvNet评估与多裁切图像（mult-crop ）评估进行比较（详情请参见3.2节）。 我们还通过softmax输出均值来评估两种评估技术的互补性。 可以看出，<u>使用多裁切图像的表现略好于密集评估，而且这两种方法确实是互补的，因为它们的组合优于其中的每一种</u>。 如上所述，我们假设这是由于对卷积边界条件的不同处理。</p><p><img src="/2020/06/16/vgg/5.png" alt></p><h3><span id="4-4-juan-ji-wang-luo-rong-he-convnet-fusion">4.4 卷积网络融合 Convnet Fusion</span><a href="#4-4-juan-ji-wang-luo-rong-he-convnet-fusion" class="header-anchor">#</a></h3><p>到目前为止，我们评估了单个ConvNet模型的性能。 在这部分实验中，我们<strong>通过模型的softmax分类后验概率均值来合并几个模型的输出</strong>。 由于模型的互补性，这提高了性能，这种方法在2012年和2013年的最优ILSVRC提交中使用过。</p><p>结果如表6所示。到ILSVRC提交时，我们只训练单尺度网络以及多尺度模型D（通过仅对完全连接层而不是所有层进行微调）。 </p><ul><li>由此产生的7个网络的融合模型具有7.3％的ILSVRC测试错误率。</li><li>提交之后，我们考虑了只有两个表现最好的多尺度模型（配置D和E）的集合，它使用密集评估将测试错误率降低到7.0％</li><li>而使用组合密集和多裁切图像评估将测试错误率则降低到6.8％。 作为参考，我们表现最佳的单模型实现了7.1％的误差（模型E，表5）。</li></ul><p><img src="/2020/06/16/vgg/6.png" alt></p><h2><span id="5-jie-lun">5. 结论</span><a href="#5-jie-lun" class="header-anchor">#</a></h2><p>在这项工作中，评估了用于大规模图像分类的深层卷积网络（多达19个权值层）。 已经证明，表示层的深度有利于分类准确性，并且通过大幅增加网络深度便可以使用传统的ConvNet架构来实现ImageNet挑战数据集上的最新性能（LeCun等，1989; Krizhevsky等， 2012）。 在附录中，我们还展示了我们的模型能很好地泛化应用于其他的任务和数据集，不亚于甚至性能优于那些深度略浅、更复杂的识别流水线。 我们的结果再一次证实了视觉表示中深度的重要性。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recognition&quot;&gt;&lt;a href=&quot;#Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recognition&quot; class=&quot;headerlink&quot; title=&quot;Very Deep Convolutional Networks for Large-Scale Image Recognition&quot;&gt;&lt;/a&gt;Very Deep Convolutional Networks for Large-Scale Image Recognition&lt;/h1&gt;&lt;div class=&quot;tocStart&quot;&gt;&lt;/div&gt;

&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-introduction&quot;&gt;1. INTRODUCTION&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-convnet-pei-zhi&quot;&gt;2. ConvNet 配置&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#2-1-jia-gou&quot;&gt;2.1 架构&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#pei-zhi&quot;&gt;配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-3-tao-lun&quot;&gt;2.3 讨论&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#3-fen-lei-kuang-jia&quot;&gt;3 分类框架&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#3-1-training&quot;&gt;3.1 Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#3-2-testing&quot;&gt;3.2 Testing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#4-classification-shi-yan&quot;&gt;4. classification 实验&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#4-1-tu-xiang-dan-chi-du-ping-gu&quot;&gt;4.1 （图像）单尺度评估&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#4-2-duo-chi-du-ping-gu-multi-scale&quot;&gt;4.2 多尺度评估 multi-scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#4-3-duo-cai-qie-tu-xiang-ping-gu-muti-crop&quot;&gt;4.3 多裁切图像评估 muti-crop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#4-4-juan-ji-wang-luo-rong-he-convnet-fusion&quot;&gt;4.4 卷积网络融合 Convnet Fusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#5-jie-lun&quot;&gt;5. 结论&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
&lt;div class=&quot;tocEnd&quot;&gt;&lt;/div&gt;

&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;论文时间：2015年&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;研究内容：大规模图像识别任务下卷积网络深度对其预测准确率的影响&lt;/li&gt;
&lt;li&gt;主要贡献：使用具有非常小的（3×3）卷积滤波器（convolution filters）的架构对深度不断递增的网络进行全面评估。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;VGG模型论文探讨并证明了以下观点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用多层的卷积层组合配以小尺寸的滤波器（3 &lt;em&gt; 3），能实现大尺寸滤波器的感受野的同时，还能使参数数量更少；（其他模型可能会用11&lt;/em&gt;11，stride=4的卷积核）&lt;/li&gt;
&lt;li&gt;加深模型深度可以获得更好的分类结果&lt;/li&gt;
&lt;li&gt;训练期间分阶段降低学习率有助模型收敛；&lt;/li&gt;
&lt;li&gt;在数据增强方面，训练时：随机从rescale后的图中裁出224*224的区域（如果rescale后的图很大，那截取到的只是图中的一部分），接下来后再水平翻转，RGB通道随机变换；测试时候，将模型的全连接改成卷积。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
    
      <category term="paper" scheme="https://sunxiaojie99.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>Densely Connected Convolutional Networks</title>
    <link href="https://sunxiaojie99.github.io/2020/06/01/DCCN/"/>
    <id>https://sunxiaojie99.github.io/2020/06/01/DCCN/</id>
    <published>2020-06-01T03:28:52.000Z</published>
    <updated>2020-06-17T08:33:10.674Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="densely-connected-convolutional-networks">Densely Connected Convolutional Networks</span><a href="#densely-connected-convolutional-networks" class="header-anchor">#</a></h1><p>时间：2018-6</p><p><strong>摘要</strong>：最近的工作表明，如果在靠近输入的层和靠近输出的层之间包含更短的连接，那么卷积网络可以显著地更深、更准确、更有效。DenseNet 根据这一观察结果，将每一层以前馈的方式连接到其余的每一层。传统的具有 $L$ 层的卷积网络有 $L$ 个连接（每层与其后续层之间有一个），我们的网络拥有 $L(L+1)/2$ 个直连接（$ C_{L}^{2}$）。对于每一层，使用前面所有层的特征图作为输入，它自己的特征图作为所有后续层的输入。</p><p>DenseNet 有以下几个<strong>优点</strong>：</p><ol><li>减轻了梯度消失带来的问题</li><li>增强了特征的传播</li><li>鼓励特征重用</li><li>大大减少了参数量</li></ol><div class="toc"><!-- toc --><ul><li><a href="#yin-yan">引言</a></li><li><a href="#xiang-guan-gong-zuo">相关工作</a></li><li><a href="#densenets">DenseNets</a></li><li><a href="#shi-yan">实验</a></li><li><a href="#tao-lun">讨论</a><ul><li><a href="#model-compactness-mo-xing-jin-cou-xing">Model compactness 模型紧凑型</a></li><li><a href="#implicit-deep-supervision-yin-shi-shen-du-jian-du">Implicit Deep Supervision 隐式深度监督</a></li><li><a href="#stochastic-vs-deterministic-connection">Stochastic vs. deterministic connection</a></li></ul></li></ul><!-- tocstop --></div><p>[TOC]</p><a id="more"></a><p>源码：<a href="https://www.cnblogs.com/yjphhw/p/10034265.html" target="_blank" rel="noopener">https://www.cnblogs.com/yjphhw/p/10034265.html</a></p><p><a href="https://gitee.com/sxjhello/vision/blob/master/torchvision/models/densenet.py" target="_blank" rel="noopener">https://gitee.com/sxjhello/vision/blob/master/torchvision/models/densenet.py</a></p><h2><span id="yin-yan">引言</span><a href="#yin-yan" class="header-anchor">#</a></h2><p>各种CNN已经成为了视觉对象识别的主流机器学习方法。虽然它们最初是在20多年前引入，但直到最近才得到更近一步的发展。最初的LeNet5 包含5层，VGG 有19 层，直到 Highway Networks 和  Residual Networks（ResNets）的出现，才达到了100层之上。</p><p>随着 CNN 变得越来越深，梯度消失问题出现了：当关于输入或梯度的信息传递了很多层之后，当它到达网络的末端（或开始）时，它可能消失。 </p><p>因为<strong>梯度消失</strong>的问题，提出了许多解决办法。<u>Highway Net</u> 和 <u>ResNet</u> 通过身份连接（identity connections）将信号从一层传到下一层。<u>Stochastic depth</u> 通过随机丢弃 ResNet 在训练期间的层来获得更好的信息和梯度流。 <u>FractalNets</u> 重复组合具有不同卷积块数量的几个平行层序列，以获得较大的深度，同时在网络中保持许多 short paths。虽然不同的方法各不相同，但它们有一个共同的特征：<strong>它们均创建了从 early layers 到 later layers 的 short paths.</strong></p><p>在这篇论文中，提出了一种将这种特性提炼为简单的连接模式的架构：来确保网络各层之间最大的信息流，<strong>将所有层（具有同样大小的匹配的特征图）彼此进行直接连接</strong>。</p><p>为了保持这种前馈特性，每一层要从之前所有层中获得额外的输入，并将自身的特征图传到后续所有层中，如图1：</p><p><img src="/2020/06/01/DCCN/1.png" style="zoom:80%;"></p><p>值得注意的是：和 ResNet 相比，这里没有通过将特征求和的组合方式传到一个图层中，相反，这里采用了连接的组合方式。</p><p>因此，第 $l$ 层有 $l$ 个输入（从0开始编号），这些输入是由第 $l$ 层之前的所有卷积块的特征图组成，它自己的特征图传向了其后的  $L-l$ 个后续层。这就引入了  $L$ 层网络的  $\frac{L(L+1)}{2}$ 个连接，而不是传统的 $L$ 个连接。</p><p>因为这种<strong>密集连接的模式</strong>（dense connectivity pattern），所以顾名思义，得到了 Dense Convolutional Network (DenseNet)。</p><p>注：这种密集连接的模式的一个可能与直觉相反的效果是，<strong>它需要比传统卷积网络更少的参数</strong>，因为它不需要重新学习冗余的特征图。<u>传统的前馈结构</u>可以看作一种状态算法，这种状态从一层传递到下一层，每一层从它的前一层读取状态，并写入后面的层。虽然这种方式改变了状态，但是传递了需要保留的信息。</p><p>ResNet 通过 additive identity transformations 达到了使信息显式保持的目的。ResNet的最新变体[13]表明，许多层的贡献很小，实际上可以在训练期间随机丢弃。ResNet的参数量大很多，因为每一层都有自己的权重。</p><p>而这里提出的 DenseNet 结构将添加到网络上的信息和需要保留的信息进行了明确的区分，<strong>DenseNet 的各层都非常窄</strong>（比如，每层只有12个 filter），仅向网络的  “collective knowledge（集体知识）”  中添加一小部分特征图，并保持其余的特征图不变，最终的分类器基于网络中所有的特征图进行决策。</p><p>DenseNet 的另外一大优点是它们<strong>改善了整个网络中的信息流和梯度流</strong>，这使得它们更容易训练。每一层都能直接从损失函数和原始输入信号中获得梯度，这有助于<strong>训练更深层次的网络架构</strong>。此外，还发现密集连接有一种<strong>正则化（regularization）的效果</strong>，这减小了在小规模训练集上的任务的过拟合问题。</p><p><strong>summary：</strong></p><ol><li>需要更少的参数量</li><li>有助于训练更深的网络架构</li><li>正则化效果，解决过拟合问题</li></ol><p>【注：<u>一些 benchmark datasets</u>：CIFAR-10，CIFAR-100，SVHN，ImageNet】</p><h2><span id="xiang-guan-gong-zuo">相关工作</span><a href="#xiang-guan-gong-zuo" class="header-anchor">#</a></h2><p><u>Highway Net</u> 是首批提供一种有效地训练超过100层的端到端的网络体系结构之一。Highway Net 使用了 bypassing paths along with gating units，可以毫不费力的优化上百层。<strong>The bypassing paths</strong> 是可以更加容易地训练非常深的网络的关键。<u>ResNets</u> 就是进一步支持了这一点，在 ResNets 中，使用了  pure identity mappings 来作为 The bypassing paths。</p><p>而且， <strong>stochastic depth</strong> 通过在训练期间随机丢弃 layers，成功训练了 1202 层的 ResNet。这表明并非所有层都是必需的，并表明 <strong>deep (residual) networks 中存在大量冗余</strong>。DenseNet 便是在一定程度上受了该 observation 的启发。</p><p>一种使网络更深（例如，借助 skip connections）的正交化方法是<strong>增加网络的宽度</strong>，GoogleNet 就是这种。GoogleNet 使用 “Inception module” 将由不同大小的 filter 生成的特征图连接在一起。事实上，简单地增加 ResNets 各层 filter 的数量，就可以在足够深的网络中提升其性能。 <u>FractalNets</u> 使用这样的 wide network structure 也取得了不错的结果。</p><p>DenseNet 没有采用极深的或极宽的结构进行代表性的特征抽取，而是通过<strong>特征复用</strong>来发掘网络的潜能，生成易于训练和参数高效化的精简模型。连接不同层学习的特征图可以增加后续层的输入的变化并提高效率，这就是 <strong>DenseNet 和 ResNet 的主要区别</strong>。和将来自不同层的特征连接到一起的 Inception networks 相比，DenseNets 更加简洁高效。</p><h2><span id="densenets">DenseNets</span><a href="#densenets" class="header-anchor">#</a></h2><p>考虑一张通过卷积网络的图片 $x_0$ ，该网络包含 $L$ 层，每个层实现一个非线性转换 $H_l(·)$ ，其中 $l$ 表示层的编号，$H(·)$ 可以是诸如 Batch Normalization(BN)、rectified linear units (ReLU)、Pooling 或者 Convolution (Conv) 等操作的复合函数。我们将第 $l$ 层的输出定义为 $x_l$ </p><ol><li><p><strong>ResNet</strong>：</p><ul><li>传统的前馈卷积网络，将第 $l$ 层的输出作为输入连接到第 $l+1$ 层，产生以下转换： $x_l = H_l(x_{l-1})$ ；</li><li>ResNet 增加了一个<strong>跨层连接（skip-connection）</strong>，它使用 <strong>identity function</strong> （恒等函数）绕过了非线性变换：$x_l = H_l(x_{l-1})+x_{l-1}$ 。</li><li>ResNet 的一个优点是梯度可以直接通过 identity function 从后面的层流到较前面的层。但是， identity function （恒等函数）和输出是通过求和的方式连接到一起，可能会阻碍网络中的信息流。</li></ul></li><li><p><strong>Dense connectivity：</strong></p><ul><li><p>为了进一步改善各层间的信息流，这里提出了一个不同的连接模式：提出了从任何层向其所有后续层的直连接，如图1所示。</p></li><li><p>因此，第 $l$  层接受其前所有层的特征图作为输入：$x_l = H_l([x_0,x_1,…,x_{l-1}])$ </p></li><li><p>其中 $[x_0, x_1,…,x_l-1]$ 表示第 $0$ 到 $l-1$ 层产生的特征图的连接。</p></li><li><p>为了便于应用，我们将上式中的多输入 $[x_0, x_1,…,x_l-1]$ 连接成一个张量（ a single tensor）。</p><p><img src="/2020/06/01/DCCN/1.png" style="zoom: 67%;"></p></li></ul></li><li><p><strong>Composite function</strong>：</p><ul><li>将 $H_l(·)$ 定义为一个复合函数，它有三部分连续的操作组成：<strong>Batch Normalization、ReLU 和一个3x3的卷积操作</strong>。</li></ul></li><li><p><strong>Pooling layers：</strong></p><ul><li>当特征图的尺寸发生变化时，$x_l = H_l([x_0,x_1,…,x_{l-1}])$  中的连接操作是不可行的。然而，卷积网络的一个重要组成部分就是下采样层，它可以改变特征图的尺寸。</li><li>为了便于在我们的网络结构中使用下采样层（down-sampling layers），我们将网络划分为多个紧密相连的<strong>密集块（dense blocks）</strong>，如图2所示。</li><li>我们将块之间的层称为<strong>过渡层（transition layers）</strong>，它们进行卷积和池化操作。</li><li>本文实验中使用的过渡层包括一个 BN 层和一个 1x1 的卷积层，其次是一个 2x2 的平均池化层。</li></ul><p><img src="/2020/06/01/DCCN/2.png" style="zoom:150%;"></p><p><em>图2 ：一个拥有三个稠密块的 DenseNet 网络，两个相邻块之间的层称为过渡层，通过卷积和池化来改变特征图的大小。</em></p></li><li><p><strong>Growth rate：</strong></p><ul><li>如果每个函数 $H_l$ 产生 $k$ 个特征图，那么第 $l$ 层的输入特征图总数为：$k_0 + k × (l-1)$ ，$k_0$ 代表输入层的  channels 数量。（就是每一层的输出是 k 个特征图，前面有 $l-1$ 层，然后再把原始输入层的 $k_0$ 个输入加上）</li><li>DenseNet和现有网络结构的一个重要区别在于DenseNet具有很窄的层，例如 k=12 ，我们把<strong>超参数 <code>k</code> 称为网络的增长率（growth rate）</strong>。我们的实验表明一个较小的增长率就可以获得相对好的效果。</li><li>一种解释就是，网络的各块中的每一层都可以获得该块内其前的所有特征图，因此，可以访问网络的集体知识（“collective knowledge”）。每一层都可以将特征图看作网络的全局状态，并且可以将自己的<code>k</code>个特征图添加到这个全局状态中。<strong>增长率 <code>k</code> 调节每一层对全局状态贡献的新信息量。</strong>全局状态一经编写，就可以从网络的任何地方进行获取，并且与传统网络不同，不需要从一层复制到另一层。</li></ul></li><li><p><strong>Bottleneck layers</strong></p><ul><li>尽管每一层仅产生 k 个特征图，但它通常情况下拥有更多的输入。在每个 3x3 卷积前引入 1x1卷积作为瓶颈层（bottleneck layer ），可以减少输入特征图的数量，从而可以提高计算效率。</li><li>这样的设计对于 DenseNet 特别有效，即网络中的 bottleneck layer  ：由 $BN-ReLU-Conv(1×1)-BN-ReLU-Conv(3×3)$ 组成 $H_l$ 版本 DenseNet 称为 <strong>DenseNet-B</strong>。（B 代表 Bottleneck）</li><li>在本文的实验中，我们令每个 $1×1$ 卷积产生 $4k$ 个特征图（k 应该是增长率）。</li></ul></li><li><p><strong>Compression：</strong></p><ul><li>为了进一步提高模型的紧凑性，我们可以在过渡层减少特征图的数量。</li><li>如果一个密集块 （dense block） 包含<code>m</code>个特征图，我们让其后的过渡层（transition layer）输出 $\lfloor \theta m \rfloor$ 个特征图。其中 $0 &lt; \theta \leq 1$ 被称作<strong>压缩因子（compression factor）</strong>。</li><li>当 $θ=1$ 时，通过过渡层的特征图数量不变，我们在实验中设置 $θ=0.5$</li><li>我们将同时使用了 bottleneck layer 和 $\theta &lt; 1$ 的transition layer 的 DenseNet 称作 <strong>DenseNet-BC</strong>。（ Bottleneck + Compression）</li></ul></li><li><p><strong>Implenentation Details</strong> 实现细节：</p><ul><li><p>除了 ImgageNet 以外的所有数据集，我们实验中使用的 DenseNet 都有三个 dense block ，每个块内的层数都是相等的。</p><ul><li>在进入第一个 dense block 之前，在输入图像上进行具有16 个输出通道的卷积（或者具有两倍 growth rate $k$ 的）DenseNet-BC。</li><li>对于卷积核大小（kernel size）为 3x3 的卷积层，输入的每一侧都被填充一个像素，以保持特征图的大小不变。</li><li>我们在1x1的卷积后跟一个2x2的平均池化层作为过渡层连接两个相邻的密集块。</li><li>在最后一个密集块（ dense block ）之后，执行一个全局平均池化（global average pooling），然后附加一个 softmax 分类器。</li><li>三个 dense block 内的特征图尺寸分别为 32x32、16x16 和 8x8。</li><li>作者使用了参数为 {L=40，k=12}、{L=100，k=12} 和 {L=100，k=24}的基本 DenseNet 结构进行实验。</li><li>对于 DenseNetBC 结构，评估了参数为 {L=100，k=12}、{L=250，k=24}和{L=190，k=40} 的网络。</li></ul></li><li><p>在 ImageNet 上的实验中，在 224×224 的输入图像上，我们使用了具有4个 dense block 的 DenseNet-BC 结构。初始的卷积层中包含 $2k$ 个卷积（大小为 7×7，stride 为2）；其他所有层特征图的数量均为 $k$ 。在 ImageNet 上使用的确切网络配置如表1。</p><p><img src="/2020/06/01/DCCN/3.png" style="zoom:200%;"></p></li></ul></li></ol><h2><span id="shi-yan">实验</span><a href="#shi-yan" class="header-anchor">#</a></h2><p>所有训练的网络都使用 SGD 梯度下降。</p><p>在 CIFAR 和 SVHN 上训练的 batch size为64，epoch 分别为 300 和 40 。初始学习率设置为0.1。</p><p>在 ImageNet 上，epoch 为 90，batch size 为 256，初始学习率设置为 0.1，在 epoch 为30和60的时候，学习率降低10倍。</p><h2><span id="tao-lun">讨论</span><a href="#tao-lun" class="header-anchor">#</a></h2><h3><span id="model-compactness-mo-xing-jin-cou-xing">Model compactness 模型紧凑型</span><a href="#model-compactness-mo-xing-jin-cou-xing" class="header-anchor">#</a></h3><p>通过直连接，由 DenseNet 中任何层学习得到的特征图都可以被所有的后续层所访问。这鼓励了网络中的特征虫咬，提供了更紧凑的模型。</p><p><img src="/2020/06/01/DCCN/4.png" alt></p><p>left：显示了DenseNet-BC 始终是 DenseNet 参数效率最高的变体。</p><p>middle：为了达到相同的 accuracy ，DenseNet-BC 只需要 ResNet 大约 $\frac{1}{3}$ 的参数。</p><p>right：仅具有0.8M可训练参数的 DenseNet-BC 能够达到与具有10.2M参数的1001层（激活前）ResNet相当的精度。</p><h3><span id="implicit-deep-supervision-yin-shi-shen-du-jian-du">Implicit Deep Supervision 隐式深度监督</span><a href="#implicit-deep-supervision-yin-shi-shen-du-jian-du" class="header-anchor">#</a></h3><p> DenseNet 的 accuracy 得到提升的一种解释是各个层通过 the shorter connections 接受到了来自 loss function 的额外监督。可以将 DenseNet 解读为一种 “deep supervision”。深度监督的好处是它将分类器附加到每个隐藏层，强制中间层学习具有区别性特征。</p><p>DenseNets 隐式执行类似的深度监督，网络顶部的单个分类器通过两到三个过渡层向所有层提供直接监督。然而，DenseNet 的损失函数和梯度基本上没有那么复杂，因为相同的损失函数在所有层之间共享。</p><h3><span id="stochastic-vs-deterministic-connection">Stochastic vs. deterministic connection</span><a href="#stochastic-vs-deterministic-connection" class="header-anchor">#</a></h3><p>随机连接与确定性连接，在 dense convolutional networks 和 stochastic depth regularization of residual networks 之间存在一个有趣的联系。在 stochastic depth 中， residual networks 中的层被随机丢弃，从而产生和周围层的直接连接。由于池化层从不丢弃，因此网络会产生与DenseNet类似的连接模式。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Densely-Connected-Convolutional-Networks&quot;&gt;&lt;a href=&quot;#Densely-Connected-Convolutional-Networks&quot; class=&quot;headerlink&quot; title=&quot;Densely Connected Convolutional Networks&quot;&gt;&lt;/a&gt;Densely Connected Convolutional Networks&lt;/h1&gt;&lt;p&gt;时间：2018-6&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;：最近的工作表明，如果在靠近输入的层和靠近输出的层之间包含更短的连接，那么卷积网络可以显著地更深、更准确、更有效。DenseNet 根据这一观察结果，将每一层以前馈的方式连接到其余的每一层。传统的具有 $L$ 层的卷积网络有 $L$ 个连接（每层与其后续层之间有一个），我们的网络拥有 $L(L+1)/2$ 个直连接（$ C_{L}^{2}$）。对于每一层，使用前面所有层的特征图作为输入，它自己的特征图作为所有后续层的输入。&lt;/p&gt;
&lt;p&gt;DenseNet 有以下几个&lt;strong&gt;优点&lt;/strong&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;减轻了梯度消失带来的问题&lt;/li&gt;
&lt;li&gt;增强了特征的传播&lt;/li&gt;
&lt;li&gt;鼓励特征重用&lt;/li&gt;
&lt;li&gt;大大减少了参数量&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;tocStart&quot;&gt;&lt;/div&gt;

&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#yin-yan&quot;&gt;引言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#xiang-guan-gong-zuo&quot;&gt;相关工作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#densenets&quot;&gt;DenseNets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#shi-yan&quot;&gt;实验&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#tao-lun&quot;&gt;讨论&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#model-compactness-mo-xing-jin-cou-xing&quot;&gt;Model compactness 模型紧凑型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#implicit-deep-supervision-yin-shi-shen-du-jian-du&quot;&gt;Implicit Deep Supervision 隐式深度监督&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#stochastic-vs-deterministic-connection&quot;&gt;Stochastic vs. deterministic connection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
&lt;div class=&quot;tocEnd&quot;&gt;&lt;/div&gt;

&lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="paper" scheme="https://sunxiaojie99.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>Point cloud learning</title>
    <link href="https://sunxiaojie99.github.io/2020/04/30/3D%20Point%20Clouds/"/>
    <id>https://sunxiaojie99.github.io/2020/04/30/3D%20Point%20Clouds/</id>
    <published>2020-04-30T01:20:00.000Z</published>
    <updated>2020-05-16T09:39:08.661Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="san-wei-dian-yun-shen-du-xue-xi-yan-jiu-zong-shu">三维点云深度学习研究综述</span><a href="#san-wei-dian-yun-shen-du-xue-xi-yan-jiu-zong-shu" class="header-anchor">#</a></h1><p>论文：Deep Learning for 3D Point Clouds: A Survey</p><p>作者：Yulan Guo</p><p>时间：2019-12</p><h2><span id="yin-yan">引言</span><a href="#yin-yan" class="header-anchor">#</a></h2><p><strong>动机</strong>：Point cloud learning （点云学习）由于在视觉、自动驾驶、机器人等方面的广泛应用，近年来受到了广泛的关注。最近，随着点云的深度学习变得更加兴旺，人们提出了许多方法来解决这一领域的不同问题。为了促进未来的研究，本文对点云深度学习方法的最新进展进行了全面的综述。</p><a id="more"></a><p><strong>挑战</strong>：</p><ol><li><p>深度学习技术目前已经成为成功解决各种二维视觉问题的主流技术，点云的深度学习依然处于初级阶段。</p></li><li><p>深度神经网络处理点云所面临的独特挑战（例如数据集的小规模、高维和三维点云的非结构化性质）</p></li></ol><p><strong>意义</strong></p><ol><li>第一篇全面涵盖几个重要点云相关任务的深度学习方法的调查论文，包括三维形状分类、三维目标检测和跟踪以及三维点云分割。</li><li>与现有的综述不同，特别关注3D点云的深度学习方法，而不是所有类型的3D数据</li><li>介绍了点云深度学习的最新进展。因此，它为读者提供了最先进的方法</li><li>提供了在几个公开可用数据集上<u>对</u><u>现有方法进行的综合比较</u>，并提供了简要总结和有洞察力的讨论</li></ol><p><strong>论述的三个主要的任务</strong>：</p><ol><li>3D shape classification （三维形状分类）</li><li>3D object detection and tracking （三维对象检测和追踪）</li><li>3D point cloud segmentation （三维点云分割）</li></ol><p><strong>三维点云深度学习方法的分类</strong>：</p><p><img src="/2020/04/30/3D%20Point%20Clouds/a.png" alt="a"></p><h2><span id="2-3d-shape-classification">2、3D Shape Classification</span><a href="#2-3d-shape-classification" class="header-anchor">#</a></h2><p><strong>介绍</strong>：这类的方法通常先学习 embedding of each point （每个点的嵌入），然后使用 aggregation method （聚合方法）从 whole point cloud （整个点云）中 extract a global shape embedding  （提取全局形状嵌入） ，最终由几个全连接层来实现 classification （分类）。</p><p>基于对每个点进行 feature learning （特征学习）的方式，现有的 3D shape  classification methods （三维形状分类方法）可分为 <strong>projection-based networks</strong> （基于投影的网络）和 <strong>point-based networks</strong> （基于点的网络）。在本文中，我们主要关注基于点的网络，但也包括一些基于投影的网络以保证完备性。</p><ol><li><strong>Projection-based methods</strong> ：首先将一个 unstructured （非结构化）的点云投影到一个规则中间的表示中，然后利用成熟的2D或3D卷积来实现形状分类。</li><li><strong>point-based networks</strong>：基于点的方法直接作用于原始点云，而不需要任何体素化或投影。基于点的方法不会引入显式信息丢失，并且变得越来越流行。</li></ol><p><strong>按时间顺序概述3D shape classification 的一些里程碑的方法</strong>：</p><p><img src="/2020/04/30/3D%20Point%20Clouds/b.png" alt="b"></p><h3><span id="2-1-projection-based-networks-ji-yu-tou-ying-de-wang-luo">2.1 Projection-based Networks 基于投影的网络</span><a href="#2-1-projection-based-networks-ji-yu-tou-ying-de-wang-luo" class="header-anchor">#</a></h3><p>基于投影的网络将3D点云投影到不同的表示模式（例如，多视图、体积表示）中，以进行特征学习和形状分类。</p><h4><span id="2-1-1-multi-view-representation-duo-shi-jiao-biao-shi">2.1.1 Multi-view representation 多视角表示</span><a href="#2-1-1-multi-view-representation-duo-shi-jiao-biao-shi" class="header-anchor">#</a></h4><p>这些方法首先将3D对象投影到多个 views (视图) 中并提取相应的 view-wise features（视域特征），然后融合这些特征以实现准确的对象识别。<strong>关键挑战</strong>是如何将多个 view-wise features 聚合到一个有识别力的全局表示 global representation 中。</p><p><strong>现有的一些方法</strong>：</p><ol><li><strong>MVCNN</strong>： 开创性的工作，只是简单地 max-pools multi-view features(多视图特征) into a global descriptor（全局描述符），但是max-pooling 仅保留特定视图中的最大元素，从而会导致信息丢失。</li><li><strong>MHBN</strong>：  通过协调双线性 pooling 来集成局部卷积特征（local convolutional features），以产生紧凑的全局描述符（global descriptor）。</li><li>首先利用关系网络（relation network）来发现一组视图上的相互关系(例如，区域-区域关系和视图-视图关系)，然后聚集这些视图以获得可辨别的 3D object representation。</li><li>……</li></ol><h4><span id="2-1-2-volumetric-representation-ti-su-biao-shi">2.1.2 Volumetric representation 体素表示</span><a href="#2-1-2-volumetric-representation-ti-su-biao-shi" class="header-anchor">#</a></h4><ol><li>早期的方法通常使用建立在 3D point clouds （3D点云）的 volumetric representation（体表示：由称为体素的离散体组成）上的三维卷积神经网络(CNN)。</li><li>Wu et al. 提出了一种卷积深度 belief-based 的3D ShapeNets，用于从不同形状的三维形状中学习点的分布。虽然已经取得了令人鼓舞的性能，但是这些方法不能很好地扩展到密集的3D数据，因为计算和内存占用随着分辨率的提高而成倍增长。</li><li>为此，引入了一种层次紧凑的图结构(如八叉树 octree )来降低这些方法的计算和存储开销。eg：OctNet、Octree-based CNN… 与基于dense input grids的 baseline network 相比，OctNet对高分辨率点云所需的内存和运行时间要少得多 。</li><li>PointGrid的混合网络，该网络集成了点和网格表示，以实现高效的点云处理。</li></ol><h3><span id="2-2-point-based-networks-ji-yu-dian-de-wang-luo">2.2 Point-based Networks 基于点的网络</span><a href="#2-2-point-based-networks-ji-yu-dian-de-wang-luo" class="header-anchor">#</a></h3><p>根据用于每个点的特征学习的网络结构，这类方法可分为逐点MLP（pointwise MLP）、基于卷积（convolution-based）、基于图（graph-based）、基于数据索引的网络（data indexing-based networks）和其他典型网络。  </p><h4><span id="2-2-1-pointwise-mlp-networks">2.2.1 Pointwise MLP Networks</span><a href="#2-2-1-pointwise-mlp-networks" class="header-anchor">#</a></h4><p>这类方法使用多层感知器 MLP（Multi-Layer Perceptrons ）对各个点进行独立的建模，接着使用对称的函数来集成到全局特征。对于无序的3D点云数据，这类网络可以得到置换不变性。然而这样的方法并未考虑到3D点之间的几何关系，如下图3。</p><p><img src="/2020/04/30/3D%20Point%20Clouds/pw.png" alt="pw" style="zoom: 67%;"></p><p>作为先驱工作，<strong>PointNet</strong> 使用MLP学习Pointwise特征，接着使用最大池化层来提取全局的形状特征。最后的分类结果也使用MLP来得到。[26]也论证了，得到置换不变性的关键在于将所有表示（representations）加起来并且使用非线性变化。[26]也设计了基础的网络DeepSets来进行多种应用的实现，包括形状分类。</p><p>由于特征是针对PointNet[5]中的每个点独立学习的，因此各个点之间的局部结构信息无法得到。[27]提出了一种分层次的网络<strong>PointNet++</strong>，从各个点之间的邻居来获取细粒度的几何特征。（PointNet++的核心，其abstraction level 由采样层（the sampling layer）、分组层（the grouping layer）和PointNet层三层组成。PointNet++通过堆叠多个abstraction level，可以从局部几何结构中学习特征，并逐层抽象局部特征。）</p><p>因为PointNet的简单和有效性，许多工作都基于PointNet开展。（这里介绍了一些网络）</p><h4><span id="2-2-2-convolution-based-networks-ji-yu-juan-ji-de-wang-luo">2.2.2 Convolution-based Networks 基于卷积的网络</span><a href="#2-2-2-convolution-based-networks-ji-yu-juan-ji-de-wang-luo" class="header-anchor">#</a></h4><p>与2D卷积相比，由于点云的不规则性，3D点云的卷积核更难设置。根据卷积核的不同，目前的3D卷积网络可以被分为连续卷积网络（continuous convolution networks ）和离散卷积网络（discrete convolution networks），如下图所示。</p><p><img src="/2020/04/30/3D%20Point%20Clouds/cb.png" alt="cb" style="zoom: 67%;"></p><p><strong>3D Continuous Convolution Networks</strong>. <strong>3D连续卷积网络</strong></p><p>这类方法在连续的空间中定义卷积核，其中邻居点的权重与它和中心点的空间分布有关。</p><p><u>3D卷积可以解释为给定子集上的加权和</u>。MLP是学习权重的一种简单方法。作为RS-CNN[35]的核心层，RS-Conv将某个点周围的局部子集作为其输入，使用MLP的方法来进行卷积，学习低维关系到高维关系的映射。</p><p><u>一些方法还使用现有算法来执行卷积</u>。在PointConv[38]中，卷积被定义为对重要性采样的连续3D卷积的蒙特卡洛估计。卷积核由加权函数（由MLP层学到）和密度函数（由核密度估计和MLP层学到）组成。为了提升内存和计算效率，3D卷积被简化成两部分：矩阵乘法和2D卷积，在相同的参数设置下，内存消耗可减小64倍。</p><p><strong>3D Discrete Convolution Networks</strong>. <strong>3D离散卷积网络</strong></p><p>这类方法在标准的网格上定义卷积核，其中的邻居点的权重是其关于中心点的补偿（offset）。</p><p>[49]将非归一化的点云变换至归一化的网格，接着在各个网格上定义卷积核。与2D卷积不同（在各个像素上分配权重），所提的3D卷积核在网格内的所有点赋予相同的权重。对于给定点，邻域内所有点（在相同网格上）的平均特征通过之前的层来计算得到。接着，所有网格的平均特征通过加权和产生当前层的输出。</p><h4><span id="2-2-3-graph-based-networks-ji-yu-tu-de-wang-luo">2.2.3 Graph-based Networks 基于图的网络</span><a href="#2-2-3-graph-based-networks-ji-yu-tu-de-wang-luo" class="header-anchor">#</a></h4><p>基于图的网络将点云中的每个点视为图的一个顶点，并基于每个点的邻域来生成图的有向边。然后在<u>空间域或谱域</u>中执行特征学习[58]。典型的基于图的网络如图5所示。</p><p><img src="/2020/04/30/3D%20Point%20Clouds/gb.png" alt="gb" style="zoom: 67%;"></p><p><strong>Graph-based Methods in Spatial Domain 空间域中的基于图的方法</strong> .</p><p>这类方法在空间域中定义卷积和池化操作。卷积通过在空间邻域内的MLP实现，池化操作通过集成信息产生新的较粗的图。各个顶点的特征由坐标、激光强度、颜色来确定，各个边的特征由两个连接点的几何属性确定。</p><p>作为先驱工作，[58]将各个点视为图的顶点，利用有向边将顶点与其邻域内的点相连，接着使用Edge-Condition Convolution（使用生成filter的网络得到，MLP等）。最大池化用来集成邻域信息，图的粗化使用VoxelGrid[59]算法得到。首先通过卷积和池化的相互交错，再跟着为全局平均池化和全连接层来产生分类score。</p><p><strong>Graph-based Methods in Spectral Domain 谱域中的基于图的方法</strong>. </p><p>这些方法将卷积定义为谱的滤波，将其实现为图上的信号与图的拉普拉斯矩阵的特征向量的乘法。</p><h4><span id="2-2-4-data-indexing-based-networks-ji-yu-suo-yin-shu-ju-de-wang-luo">2.2.4 Data Indexing-based Networks 基于索引数据的网络</span><a href="#2-2-4-data-indexing-based-networks-ji-yu-suo-yin-shu-ju-de-wang-luo" class="header-anchor">#</a></h4><p>这些网络基于不同的数据索引结构(例如，八叉树和kd-树)来构建。在这些方法中，点特征是沿着树从叶节点到根节点分层学习得到的。 </p><h4><span id="2-2-5-other-networks">2.2.5 Other Networks</span><a href="#2-2-5-other-networks" class="header-anchor">#</a></h4><p>除了上述方法外，还提出了许多其他方案</p><p>表1：在ModelNet10/40基准上比较3D Shape Classification 结果，只关注基于点的网络（pointbased networks ），“#params”指的是相应模型的参数个数。“OA”表示 overall accuracy ，“MACC”表示表中的平均精度（mean accuracy ）。符号‘-’表示结果不可用。</p><p><img src="/2020/04/30/3D%20Point%20Clouds/sc.png" alt="sc" style="zoom: 67%;"></p><h2><span id="3-3d-object-detection-and-tracking">3、3D Object Detection and tracking</span><a href="#3-3d-object-detection-and-tracking" class="header-anchor">#</a></h2><h3><span id="3-1-3d-object-detection-wu-ti-jian-ce">3.1 3D Object Detection 物体检测</span><a href="#3-1-3d-object-detection-wu-ti-jian-ce" class="header-anchor">#</a></h3><p>与普通2D中目标检测方法类似，3D中的目标检测也可以分为两类：基于候选区域的方法和直接映射方法。</p><h4><span id="3-1-1-region-proposal-based-methods-ji-yu-hou-xuan-qu-yu">3.1.1 Region Proposal-based Methods 基于候选区域</span><a href="#3-1-1-region-proposal-based-methods-ji-yu-hou-xuan-qu-yu" class="header-anchor">#</a></h4><p>首先产生一些可能包含物体的区域（Proposals），接着对各个区域提取特征，来决定各个候选区域的物体类别。</p><p><strong>根据不同的产生候选区域的方法</strong>，这些方法可进一步分为三类：基于多视角的方法（multi-view based）；基于分割的方法（segmentation-based）以及基于锥体的方法（frustum-based methods）。  </p><h5><span id="multi-view-methods-duo-shi-jiao-de-fang-fa">Multi-view Methods 多视角的方法</span><a href="#multi-view-methods-duo-shi-jiao-de-fang-fa" class="header-anchor">#</a></h5><p>这类方法从不同的视角图像（雷达前景图（LiDAR front view），鸟瞰图（bird’s eye view (BEV) ），图像（image）等）中融合各个候选框的特征，来产生3D rotated boxes，如图7(A)所示。这些方法的计算成本通常很高。</p><p>在[4]中，Chen等人从鸟瞰图BEV中产生一组准确的3D候选框，并且将其投影到其它视角中（雷达前景图，RGB图像），接着将各个区域的特征组合到一起，来预测有方向的3D bounding boxes。尽管这种方法在0.25IOU， 300个候选框设置时达到了99.1%的recall，但是速度非常慢。</p><p><img src="/2020/04/30/3D%20Point%20Clouds/mv3d.png" alt="mv3d" style="zoom: 50%;"></p><p>后续的基于多视角的3D物体检测方法主要从以下两个方面来提升。</p><ul><li>（1）<strong>提出了很多方法来有效的融合不同模态之间的信息</strong>。<ul><li>为了针对小物体产生有较高recall的候选框，[97]提出了一种多模态的基于融合的区域生成网络（ a multi-modal fusion-based region proposal network）。首先使用裁剪和大小调整操作从BEV视图和image视图中提取大小相等的特征，然后使用 mean pooling 对这些特征进行融合。具体而言，他们对BEV（鸟瞰视角）空间中的每个点提取最近的对应点的图image 特征，接着通过将image特征投影至BEV空间的方法，使用双线性插值得到稠密的BEV的特征图。<strong>实验结果证明稠密的BEV特征图比起离散的image特征图和稀疏的LiDAR(雷达激光)特征图更加适合3D物体检测。</strong> </li><li>[99]提出了多任务，多感知器的3D物体检测网络来进行端到端的训练。具体而言，利用多种任务（2D物体检测，背景估计 ground  estimation，深度补偿  depth completion ），帮助网络学习到更好的特征表示。学习到的跨模态的表示，可进一步用来产生更准确的物体检测结果。实验证明这类方法在2D,3D,BEV detection 任务上有着非常好的提升，在TOR4D基准[100, 101]上超越了之前的SOTA。</li></ul></li><li>（2）<strong>其它的一些方法致力于提取输入数据更鲁棒的表示 representations  </strong><ul><li>[102]通过引入空间Channel注意力机制模块（Spatial Channel Attention  (SCA)  Module），探索了多尺度的环境信息，该模块可捕获全局的以及多尺度的场景环境，加强了有用的特征。同样的，他们还提出了一种 Extension Spatial Unsample  (ESU) 模块，通过组合多尺度的低层特征来获得具有丰富空间信息的高层特征，从而生成更可靠的3D物体候选框 （proposals） 。尽管达到了更好的检测效果，但上述所提的多视角方法都需要较长的运行时间，因为他们对每个候选框都进行了特征的池化。因此，[103]使用了 预ROI池化卷积（pre-ROI pooling convolution）来提高[4]的效率。具体而言，他们将大部分的卷积操作移动到 RoI pooling 模块之前。因此，对于所有的物体候选框，ROI卷积只使用一次。实验结果显示这类方法可达到11.1fps, 速度达到了MV3D[4]的5倍。</li></ul></li></ul><h5><span id="segmentation-based-methods-ji-yu-fen-ge-de-fang-fa">Segmentation-based Methods 基于分割的方法</span><a href="#segmentation-based-methods-ji-yu-fen-ge-de-fang-fa" class="header-anchor">#</a></h5><p>这些方法首先利用现有的语义分割技术去除大多数背景点，然后在前景点上生成大量高质量的候选框，以节省计算量，如图7(B)所示。</p><p><img src="/2020/04/30/3D%20Point%20Clouds/sb.png" alt="sb" style="zoom: 67%;"></p><p>与刚刚的多视角Multi-view的方法[4],[97],[103]相比，这类方法达到了更好的物体recall，并且更适合一些目标高度遮挡和拥挤的复杂场景。</p><p>[104]中，Yang et al使用了2D的分割网络来预测前景（foreground pixels）的像素并将其投影至点云中，以此来剔除掉多数的背景点。接着在这些前景点中生成候选框，并且设计了一种新的标准称之为PointsIoU来减少候选框的冗余性和模糊性。</p><p>跟着[104]的脚步，[105]提出了PointRCNN的框架。具体而言，他们直接对3D点云进行分割，然后得到前景点，并且将语义特征和局部空间特征融合从而得到高质量的3D boxes。</p><p>[106] following [105]中的RPN，提出了一种利用图卷积网络来进行3D物体检测。具体而言，利用图卷积，引入了两个模块来改进refine物体的候选框。第一个模块R-GCN利用一个候选框中的所有点，得到每个候选框的特征集成。第二个模块C-GCN将所有候选框中的每一帧信息融合起来，利用环境来回归准确的物体boxes。</p><p>[107]将点云投影至基于图像 image-based 的分割网络的输出，并将语义预测值附加到这些点上。</p><p>[109]得到了显著的性能提升，通过将涂色的点送入至一些检测器中[105, 108]。</p><p>[110]将每个点与spherical anchor相关联，每个点的语义值用来移除多余的anchors。这样的方法得到了更好的recall以及有着更小的计算消耗。与此同时，文中提出了PointsPool层，对候选框中的内部点学习相容的特征（compact features），并且引入了并行的IoU来提高位置的准确度的检测性能。</p><p>实验结果证实这样的方法在KITTI数据集[10]上较难的集合（car class）的性能比[99, 105, 111]的性能优越很多，并达到了12.5fps。</p><h5><span id="frustum-based-methods-ji-yu-zhui-ti-de-fang-fa">Frustum-based Methods 基于椎体的方法</span><a href="#frustum-based-methods-ji-yu-zhui-ti-de-fang-fa" class="header-anchor">#</a></h5><p>这类方法首先利用现有的2D物体检测子，产生2D的候选矩形框，接着对每个2D的候选框提取3D的锥体候选框，如下图所示。尽管这类方法可以有效地给出3D物体的坐标，但step-by-step步进式的pipeline流水线使得它们的性能受到2D图像检测子的限制。</p><p><img src="/2020/04/30/3D%20Point%20Clouds/fb.png" alt="fb" style="zoom: 67%;"></p><p>F-PointNets[112]为此类detection方向的先驱工作。它在每个2D区域上产生一个锥形的候选框（frustum proposal），并且应用PointNet[5] ( 或PointNet++[27] ) 来学习各个3D锥体的点云特征，从而进行3D box的估计。</p><p>在随后的工作中，[113]提出了Point-SENet模块，来预测一系列的缩放因子，从而被用来突出有用特征和抑制无用特征。同时他们也将PointSIFT[114]模块集成至网络中，来获取点云的方向信息，其可以得到对形状尺度的强鲁棒性。该方法在[10], [115]的数据集上，与F-PointNets[112]相比得到了显著的提高。</p><p>方法[116]利用了2D image 区域和对应的锥体点来回归3D boxes。为了融合image 特征和点云的全局特征，他们提出了全局的融合网络来直接回归box的角坐标。他们也提出了稠密的网络网络来预测各个点对于各个角的补偿（offsets）。</p><p>[117]第一次从2D图像中估计2D的bounding boxes和3D物体姿态，提取多个几何上可行的对象候选。这些3D候选对象被送入至box 回归网络来预测准确的3D物体boxes。</p><p>[111]对于各个2D区域，在锥体轴上产生一系列的锥体，并使用PointNet来对各个锥体提取特征。锥体层次的特征用来产生2D特征图，再被送入至FCN 全连接网络来估计3D box。该方法在基于2D图像的方法中达到了state-of-the-art的性能，并且在KITTI积分榜上排在很靠前的位置。</p><p>[118]首先在鸟瞰图BEV上得到初步的检测结果，接着基于鸟瞰图的预测结果，提取小部分点的子集，再应用局部的微调网络来学习局部特征，预测高精度的3D bounding boxes。</p><h5><span id="qi-ta">其他</span><a href="#qi-ta" class="header-anchor">#</a></h5><p>……</p><h4><span id="3-1-2-single-shot-methods-zhi-jie-ying-she">3.1.2 Single Shot Methods 直接映射</span><a href="#3-1-2-single-shot-methods-zhi-jie-ying-she" class="header-anchor">#</a></h4><p>这类方法使用单阶段的网络，直接预测类别概率和回归物体的3D bounding boxes。这类方法不需要产生区域候选框和后处理。结果是，这类方法有着很快的速度，很适合实时的应用。<strong>根据输入数据的形式</strong>，single shot方法可分为两类：<u>基于鸟瞰图的方法</u>和<u>基于点云的方法</u>。</p><h5><span id="bev-based-methods-ji-yu-niao-kan-tu-de-fang-fa">BEV-based Methods 基于鸟瞰图的方法</span><a href="#bev-based-methods-ji-yu-niao-kan-tu-de-fang-fa" class="header-anchor">#</a></h5><p><u>这类方法将BEV表示作为输入。</u></p><p>[100]将场景的点云离散化，使用FCN来预测物体的位置和航向角。该方法超越了大多数single shot 方法([125],[126],[127])并且达到了28.6fps。之后，[128]利用HP map（High-Definition 高清）提供的几何和语义先验信息，提高了[100]的鲁棒性和检测性能。</p><h5><span id="point-cloud-based-methods-ji-yu-dian-yun-de-fang-fa">Point Cloud-based Methods.  基于点云的方法</span><a href="#point-cloud-based-methods-ji-yu-dian-yun-de-fang-fa" class="header-anchor">#</a></h5><p><u>这类方法将点云转换至一般的表示（例如2D map），接着使用CNN来预测对象的类别和3D boxes</u>。</p><p>[125]提出了使用FCN进行 3D object detection 。他们将点云转换至2D point map，使用2D FCN来预测bounding boxes和物体的置信度。</p><p>之后，[126]将点云离散化至4D的张量，其维度分别为：长度，宽度，高度和channel，接着将2D FCN的方法延伸至3D来进行3D的物体检测（object detection）。与[125]相比，基于FCN的3D方法达到了大于20%准确率的收益，但是由于3D卷积核数据的稀疏性，消耗了更多的计算资源。</p><p>为了解决体素 voxels 稀疏性的问题，[127]利用了feature-centric voting scheme（特征为中心投票机制），为每个非空的体素生成一组的votes，最后通过将votes相加的方式得到卷积的结果。它的计算复杂度与被占据的体素数量成正比。</p><p>[130]通过堆叠多个稀疏3D CNN，构建了3D的backbone网络。这样的设计节约了内存并且加速了计算。这个3Dbackbone网络提取了丰富的物体检测的3D特征，并且并未引入计算量的负担。</p><p>[108]提出了基于体素的端到端的可训练框架VoxelNet。他们将点云分割成等间距的体素，将每个体素的特征编码成4D的张量。然后使用RPN（region proposal<br>network）网络来产生检测结果（detection results）。尽管该方法效果很好，但由于体素的稀疏性和3D卷积操作，该方法运行速度很慢。之后，[120]使用了稀疏的卷积网络[134]来提高[108]的推断效率。</p><p>[131]通过将图像和点云特征在早期融合的方式，扩展了VoxelNet的工作。具体而言，他们将[108]产生的非空体素投影至图像，使用预训练的网络对各个投影的体素提取图像特征。这些图像特征与体素特征相级联，来预测准确的3D boxes。这类方法利用了多模态的信息，来减少false postivies and negatives。</p><p>[109]提出了3D物体检测子称为PointPillars。该方法利用了PointNet来学习点云的特征，将这些学到的特征编码伪图像（pesudo images）。然后使用2D的物体检测流水线（pipeline）来预测3D bounding boxes（边界框）。PointPillars在Average Precision（平均精度 AP）的指标上，超越了大多数的融合方法（MV3D[4], RoarNet[117], AVOD[97]）。并且，PointPillars在3D和BEV KITTI benchmarks上达到了62fps。</p><h5><span id="other-methods">Other Methods</span><a href="#other-methods" class="header-anchor">#</a></h5><p>[132]提出了一种有效的3D目标检测子称之为LaserNet。该方法在各个点上预测bounding boxes的概率分布，然后结合各个点的分布来产生最后的3D object boxes。接着，点云的dense range view representation （密集视图(RV)表示）作为输入，使用 fast mean-shift algorithm来降低逐点预测产生的噪声。LaserNet在0到50米的范围内实现了最先进的性能，其运行时间明显低于现有的方法。</p><p>[133]扩展LaserNet以利用RGB图像提供的密集纹理(例如，50到70米)。具体来说，通过将3D点云投影至2D图像使得LiDAR点和image点关联，并利用这种关联将RGB信息融合到3D点中。他们还将3D语义分割作为辅助任务以learn better representations。该方法在保持LaserNet的高效率的同时，在长距离(例如50到70米)目标检测和语义分割方面都取得了显著的改进。</p><h3><span id="3-2-3d-object-tracking-3d-wu-ti-gen-zong">3.2 3D Object Tracking 3D物体跟踪</span><a href="#3-2-3d-object-tracking-3d-wu-ti-gen-zong" class="header-anchor">#</a></h3><p>给定一个物体在第一帧时的位置，目标跟踪的任务是估计它在之后帧的状态。由于3D物体跟踪可以使用点云中丰富的几何信息，人们期待用它来克服在2D图像上追踪任务的困难，包括遮挡，光照以及尺度的变化。</p><p>Siamese network……</p><h3><span id="3-3-3d-scene-flow-estimation">3.3 3D Scene Flow Estimation</span><a href="#3-3-3d-scene-flow-estimation" class="header-anchor">#</a></h3><p>类似于2D视觉中的光流估计，已经有几种方法开始从点云序列中学习有用的信息(如三维场景流、空间临时信息)。</p><p>[142]提出了FlowNet3D，在一系列连续点云中直接学习场景流（scene flows）。FlowNet3D通过flow embedding layer， 学习point-level的特征和运动特征（motion features）。然而FlowNet3D存在两个问题。第一，一些预测的运动向量（motion vectors）与真实值差别非常大；第二，很难将FlowNet应用至非静态的场景，尤其是有着可形变物体的场景。</p><p>为了解决该问题，[143]引入了余弦距离的损失函数来最小化预测值与真实值之间的夹角。同时，他们提出了point-to-plane的距离损失函数，来提高刚性的和动态的场景的准确率。实验结果显示这两种损失函数将FlowNet3D的准确率从57.85%提升至63.43%，并且加速和稳定了训练过程。</p><p>[144]提出了HPLFlowNet（Hierarchical Permutohedral Lattice FlowNet ），从大规模的点云中直接估计场景流。文中提出了一些bilateral convolutional layers来存储结构信息，同时降低计算消耗。</p><p>为了有效地处理序列点云，[145]提出了PointRNN, PointGRU和PointLSTM，以及一个sequence-to-sequence model 来追踪移动点（moving points）。PointRNN, PointGRU和PointLSTM能够捕捉空间-时间信息，并且建模动态的点云。</p><p>类似地，[146]提出了MeteorNet来直接从动态点云中学习表示。该方法试图从时间和空间上的邻近点学习总体特征。</p><p>[147]提出了两个自监督的损失函数，在大量无标签的数据集上训练网络。他们的主要思想是：一种鲁棒的场景流估计方法应该在向前预测和向后预测时均有效。由于场景流标注不可用，预测得到的转换后的点的最近点，被当做是假想的真实值。然而，真正的真实值可能与它不同。为了避免这个问题，他们在相反的方向计算场景流，并且提出了cycle consistency loss。实验结果显示这种自监督的方法超过了现有自监督学习方法中的SOTA（state-of-the-art）性能。</p><h3><span id="3-4-summary">3.4 Summary</span><a href="#3-4-summary" class="header-anchor">#</a></h3><p>KITTI基准是自动驾驶领域中最有影响力的，并且在学术和工业领域有着广泛的应用。表2和表3展示了不同方法在KITTI test 3D and BEV benchmark上的结果。</p><p><img src="/2020/04/30/3D%20Point%20Clouds/t2.png" alt="t2" style="zoom: 67%;"></p><p><img src="/2020/04/30/3D%20Point%20Clouds/t3.png" alt="t3" style="zoom: 67%;"></p><p>可以观察到：</p><ul><li>Region proposal-based methods 是最常见的方法，在KITTI test 3D， BEV上的性能均超出了single shot methods。</li><li>现有的3D目标检测子（3D object detectors）有两个限制。第一，长范围的检测能力较弱。第二，如何充分利用图像中的纹理信息（texture information）仍然是个公开的问题。</li><li>多任务学习（ Multi-task learning）是在3D目标检测中未来的方向。例如，[99]通过合并多种任务，学习跨模态的表示来得到SOTA的检测效果。</li><li>3D物体跟踪（ 3D object tracking）和场景流估计（scene flow  estimation）是较新的研究方向，自2019年来受到越来越多的关注。</li></ul><h2><span id="4-3d-point-cloud-segmentation">4、3D Point Cloud Segmentation</span><a href="#4-3d-point-cloud-segmentation" class="header-anchor">#</a></h2><p>3D点云分割既需要了解全局的几何结构，又需要了解每个点的细粒度细节。根据分割的粒度，3D点云分割方法可分为以下三类：语义分割（场景级 scene level)）、实例分割（物体级 object level）和 part segmentation（part level）。</p><h3><span id="4-1-3d-semantic-segmentation-3d-yu-yi-fen-ge">4.1 3D Semantic Segmentation 3D 语义分割</span><a href="#4-1-3d-semantic-segmentation-3d-yu-yi-fen-ge" class="header-anchor">#</a></h3><p>给定一个点云，语义分割的目标是，根据语义信息，将各个点分成一定的子集。与3D shape classification（第2节）的分类类似，语义分割可分为两种方法：基于投影的方法和基于点的方法。</p><h4><span id="4-1-1-projection-based-networks-ji-yu-tou-ying-de-wang-luo">4.1.1 Projection-based Networks 基于投影的网络</span><a href="#4-1-1-projection-based-networks-ji-yu-tou-ying-de-wang-luo" class="header-anchor">#</a></h4><p>Intermediate regular representations（中间正则表示）可被分成以下几种：多视角(multi-view)表示[148], [149]、球状(spherical)表示[150], [151], [152]、体素(volumetric)表示[153], [154], [155]、超多面体晶格(permutohedral lattice )表示[156], [157]以及混合(hybrid)表示[158], [159]。具体可见下图。</p><p><img src="/2020/04/30/3D%20Point%20Clouds/pb.png" alt="pb" style="zoom: 50%;"></p><h5><span id="4-1-1-1-duo-shi-jiao-biao-shi-multi-view-representation">4.1.1.1 多视角表示 Multi-view Representation</span><a href="#4-1-1-1-duo-shi-jiao-biao-shi-multi-view-representation" class="header-anchor">#</a></h5><p>[148]首先将3D点云从多个虚拟的相机视角投影至2D平面上，接着，使用 multi-stream FCN 对合成图像进行像素级分数预测。最终，通过融合不同视图上的重投影分数（re-projected scores ）来获得每个点的最终语义标签。</p><p>相似地，[149]首先利用多个相机位置，得到点云的一些RGB和深度图快照。接着使用2D segmentation networks ，对这些快照进行像素级的标注label，使用残差校正(residual correction)进一步融合从RGB和深度图像预测的分数。</p><p>基于点云是从局部欧式曲面上采样得到的假设， [161]引入了tangent convolutions进行稠密的点云分割。该方法首先将各个点周围的局部曲面投影至虚拟的切平面。Tangent convolutions在曲面上直接进行。该方法具有很强的可扩展性，能够处理几百万个点的大规模点云。</p><p>总的来说，多视角分割方法的性能对视角的选择(viewpoint selection)和遮挡(occlusions)非常敏感。同时，这类方法并未能完全利用潜在的几何和结构信息，因为投影操作不可避免地引入了信息损失。</p><h5><span id="4-1-1-2-qiu-zhuang-biao-shi-spherical-representation">4.1.1.2 球状表示 Spherical Representation</span><a href="#4-1-1-2-qiu-zhuang-biao-shi-spherical-representation" class="header-anchor">#</a></h5><p>为了得到更快更准确的3D点云分割，[150]提出了基于SqueezeNet和条件随机场(Conditional Random Field (CRF))的端到端的网络。</p><p>为了进一步提升分割准确率，引入了SqueezeSegV2[151]，通过使用无监督的domain adaptationpipeline  解决domain shift 问题。</p><p>[152]提出了RangeNet++，针对LiDAR点云进行<u>实时</u>语义分割。首先将2D深度图像的语义标签转移至3D点云上，然后使用基于KNN的后处理步骤来减缓离散化误差和推理输出模糊的问题。</p><p>与单一的视角映射相比，球映射保持了更多的信息，并且更适合激光雷达（LiDAR）点云的标注。然而，这样的中间表示不可避免地引入了一些问题，比如离散化误差和遮挡问题。</p><h5><span id="4-1-1-3-ti-su-biao-shi-volumetric-representation">4.1.1.3 体素表示 Volumetric Representation</span><a href="#4-1-1-3-ti-su-biao-shi-volumetric-representation" class="header-anchor">#</a></h5><p>[163]首先将点云分成一系列占有的体素（occupancy voxels）。接着将这些中间数据送入至fully-3D CNN中进行体素级别的segmentation。最后，为一格体素（a voxel）内的所有点分配与该体素相同的语义标签label。该方法的性能极其受限于体素粒度(granularity of the voxels )和点云分割引起的边界伪影(boundary artifacts)。</p><p>之后，[164]提出SEGCloud来得到更细粒度和全局一致(global consistent)的语义分割。该方法引入了确定性的三线性插值，将由3D-FCNN产生的粗糙的体素预测映射回点云中，接着使用Fully Connected CRF，确保推测出的点云有着空间上的一致性。</p><p>[153]引入了一种基于核的变分自编码器结构，对每个体素内部的局部几何结构进行编码。这里摒弃了binary occupancy representations， 使用RBF得到连续的表示，并捕获到每个体素中点的分布。再使用VAE将各个体素中的点分布映射至紧凑的隐空间，最后使用CNN得到鲁棒的特征表示。</p><p><u>良好的可扩展性是体素表示中的优点之一</u>。具体而言，基于体素的网络（volumetric-based networks）可以在不同空间大小的点云中自由训练和测试。在Fully-Convolutional Point Network（FCPN）中，首先从点云中提取出来不同级别的几何相关性，再使用3D卷积和加权的average pooling 来提取特征、合并依赖关系。该方法可处理大规模的点云，并且在推断时有着良好的尺度扩展性质(scalability)。</p><p>[166]提出了ScanComplete来实现3D补全，以及对各个体素进行语义标注。该方法利用了全卷积网络(fully-convolutional neural networks)的尺度扩展性(scalability)，在训练和测试阶段可以适应不同大小的输入数据。使用从粗到细的策略来提高预测结果的分辨率。</p><p>很自然地，体素表示是稀疏的，其中非零元素的数量仅仅占很小一部分。因此，在空间上稀疏的数据使用稠密的卷积网络是比较无效的。为此，[155]提出了子流形的稀疏卷积网络( submanifold sparse convolutional networks)。该方法通过限制卷积的输出只能与被占据的体素有关，从而显著降低了内存和计算成本。同时，该稀疏卷积还可以控制提取出的特征的稀疏性。该子流形稀疏卷积很适合处理高维度且空间较稀疏的数据。</p><p>更进一步，[167]提出了一种用于三维视频感知的4D时空卷积神经网络（4D spatio-temporal convolutional neural network）“Minkowski Net”。</p><p>综上所述，体素表示很自然地保留了3D点云的邻域结构。其规范的数据形式还允许直接应用标准3D卷积。这些因素导致了该领域性能的稳步提高。然而，体素化的过程内在地引入了离散化的伪影和信息损失。通常，高分辨率会导致较高的内存和计算消耗，低分辨率引入了信息的损失。在实际中如何选择合适的网格分辨(grid resolution)率是non-trivial(不平凡的)的。</p><h5><span id="4-1-1-4-chao-duo-mian-ti-jing-ge-biao-shi-permutohedral-lattice-representation">4.1.1.4 超多面体晶格表示 Permutohedral Lattice Representation</span><a href="#4-1-1-4-chao-duo-mian-ti-jing-ge-biao-shi-permutohedral-lattice-representation" class="header-anchor">#</a></h5><p>[156]提出了基于双边卷积层（Bilateral convolution layers -BCLs）的稀疏晶格网络（Sparse Lattice Networks -SPLATNet）。该方法首先将原始点云插入至超多面体稀疏晶格(permutohedral sparse lattice)，再使用BCL对占据的部分进行卷积。得到的输出再重新插回原始点云。此外，该方法还允许灵活地联合处理多视图图像和点云。</p><p>更进一步，[157]提出了LatticeNet来实现有效的处理大规模点云。还引入了与数据相关的插值模块 DeformsSlice，将格点要素(lattice feature)反投影到点云中</p><h5><span id="4-1-1-5-hun-he-biao-shi-hybrid-representation">4.1.1.5 混合表示 Hybrid Representation</span><a href="#4-1-1-5-hun-he-biao-shi-hybrid-representation" class="header-anchor">#</a></h5><p>为了进一步利用所有可用信息，许多方法试图学习多模态特征(multi-modal features )。</p><p>[158]提出了joint 3D-mult-view网络，来组合RGB 特征和几何特征。一个3D CNN stream 和一些2D CNN stream用来提取特征，另一个可微分的back-projection layer用来合并3D和2D特征。</p><p>更进一步，[168]提出了unified point-based network来学习2D纹理信息，3D结构和全局特征。该方法直接应用基于点的网络(point-based networks)来提取局部几何特征和环境信息。</p><p>[159]提出了Multiview PointNet（MVPNet）来集成2D多视角特征和空间几何特征。</p><h4><span id="4-1-2-point-based-networks-ji-yu-dian-de-wang-luo">4.1.2 Point-based Networks 基于点的网络</span><a href="#4-1-2-point-based-networks-ji-yu-dian-de-wang-luo" class="header-anchor">#</a></h4><p>基于点的网络直接在点云上进行操作。然而，点云通常是无序且无结构的，使得直接应用标准的CNN不现实。为此，先驱的工作PointNet[5]用来对每个点进行特征学习，使用的是标准的MLP和全局特征。基于PointNet，一系列基于点的网络被提出。总体而言，这类方法可大致分为以下几类：<u>基于各个点的MLP方法</u>(pointwise MLP method)，<u>基于点卷积的方法</u>(point convolution methods)，<u>基于RNN的方法</u>(RNN-based methods)和<u>基于图的方法</u>(graph-based methods)。</p><h5><span id="4-1-2-1-pointwise-mlp-methods">4.1.2.1 Pointwise MLP Methods</span><a href="#4-1-2-1-pointwise-mlp-methods" class="header-anchor">#</a></h5><p>这类方法通常利用共享的MLP作为网络中的基本单元。然而，由共享MLP提取出的各个点上的特征，并不能获取到点云中的局部几何关系( local geometry)，以及点与点之间的关系(mutual interactions)[5]。为了获取各个点周围更广泛的信息，以及学习到更丰富的局部结构(local structures)，有很多方法被提出，包括<u>基于邻近点特征池化的方法</u>(methods based on neighboring feature pooling)，<u>基于注意力机制的集成</u>(attention-based aggregation)以及<u>局部-全局的特征级联</u>( local-global feature concatenation)。</p><p><strong>Neighboring feature pooling</strong></p><p>为了获取局部的几何形式，这类方法通过将局部邻域点集成的方式，对各个点学习特征。具体而言，PointNet++[27]将点分层次，逐步地分成一些组，如下图所示。多尺度的grouping和多分辨率的grouping来克服点云多样性造成的问题。</p><p><img src="/2020/04/30/3D%20Point%20Clouds/pn.png" alt="pn" style="zoom: 50%;"></p><p>之后，[114]提出了PointSIFT模块来实现方向的编码和scale awareness。该模块通过使用3阶段的有向的卷积操作，将8个空间方向的信息堆叠并且编码，将多尺度的特征提取并级联来实现对不同尺度的适应性。</p><p>与PointNet++中使用GROUPING的方法不同，[169]利用K-Means聚类和KNN的方法在世界空间和特征空间定义两种邻域。基于这样的假设：来自于同一类的点在特征空间中应当接近，该论文提出了pairwise distance loss and a centroid loss来对特征学习进行正则。</p><p>为了建模点与点之间的相互关系，[31]提出了PointWeb来寻找局部区域内所有点对之间的关系。[170]提出了置换不变性的卷积称之为Shellconv。[95]提出了有效、轻量的网络称为RandLA-Net实现大规模的点云处理。该方法利用随机样本采样，在内存和计算方面提升很多。提出的局部特征集成用来获取和保持几何特征。</p><p><strong>Attention-based aggregation</strong></p><p>为了进一步提升分割的准确率，[90]针对点云分割，提出了基于注意力的机制。</p><p>[29]提出了组随机注意力机制(group shuffle attention)来建模点之间的关系，并且提出了具有置换不变性、task-agnostic以及可微分的Gumbel Subset Sampling(GSS) ，来替代被广泛应用的Furthest Point Sampling(FPS)最远点抽样方法。该方法对离群点不敏感，并且可以选择具有代表性的点的子集。</p><p>为了更好地获取点云的空间分布，[171]提出了Local Spatial Aware(LSA)层来学习空间感知权重。</p><p>与CRF类似，[172]提出了Attention-based Score Refinement(ASR)模块对分割的结果进行后处理。初始分割结果通过pooling的方式进行修正。该模块很容易被集成至其他的深度网络中来提升分割效果。</p><p><strong>Local-global concatenation</strong></p><p>[85]提出了置换不变性的PS2-Net，将点云的局部结构(local structures)和全局信息(global context)合并。重复叠加Edgeconv[60]与NetVLAD[173]，以获取局部信息和场景级别的全局特征（scene-level global features）。</p><h5><span id="4-1-2-2-point-convolution-methods-dian-juan-ji-fa">4.1.2.2 Point Convolution Methods 点卷积法</span><a href="#4-1-2-2-point-convolution-methods-dian-juan-ji-fa" class="header-anchor">#</a></h5><p>这类方法通常试图提出在点云上进行更有效的卷积操作。</p><p>[49]提出了一种逐点卷积算子，其中邻域点被合并至kernel cell，然后与核权重进行卷积。</p><p>[174]提出了称之为PCCN的网络，该网络基于参数化的连续卷积层。该层的核函数由MLP参数化，横跨连续向量空间。</p><p>[42]提出了Kernel Point Fully Convolutional Network(KP-FCNN)，基于Kernel Point Convolution(KPConv)。具体而言，KPConv的卷积权重由欧式空间的距离决定，卷积核的点数（number of kernel points）也并不固定。卷积核点（kernel points）的位置由一个最优化问题确定。</p><p>在[175]中，作者提供了丰富的消融实验（ablation experiments）和可视化结果展示了集成方法中，感受野的重要性。同时他们提出了Dilated Point Convolution(DPC)操作，来集成邻近点的特征，进而取代KNN(K nearest neighbours)的方法。该方法在提升感受野（the receptive field）上非常有效，并且可以容易地集成至 aggregation-based networks。</p><h5><span id="4-1-2-3-rnn-based-methods">4.1.2.3 RNN-based Methods</span><a href="#4-1-2-3-rnn-based-methods" class="header-anchor">#</a></h5><p>为了从点云中获取固有的上下文特征(context features )，RNN也被用来进行点云的语义分割。</p><p>基于PointNet[5]， [180]首先将一大块点云转换成多尺度的块和网格块来获取输入级别的环境。接着，使用PointNet对各个块提取特征并送入Consolidation Units 或Recurrent Consolidation Units来获取输出级别的环境信息。实验结果显示，这样处理空间环境信息的方法在提高分割性能时是很重要的。</p><p>[179]提出了一种轻量的模块，利用了slice pooling layer将无序的点云特征转换成有序的特征向量。</p><p>[181]提出了Pointwise Pyramid Pooling (3P)模块来获取从粗到细的局部特征，并利用双向的RNN来实现端到端学习。然而这类方法损失了丰富的几何特征和密度分布[189]。</p><p>[189]提出了Dynamic Aggregation Network(DAR-Net)来同时考虑全局场景复杂度和局部几何特征。</p><p>[190]提出了3DCNN-DQN-RNN。该网络首先使用3DCNN学习空间分布和颜色特征，使用DQN进一步定位类别物体。最后级联的特征向量送入RNN中获取最后的分割结果。</p><h5><span id="4-1-2-4-graph-based-methods-ji-yu-tu-de-fang-fa">4.1.2.4 Graph-based Methods 基于图的方法</span><a href="#4-1-2-4-graph-based-methods-ji-yu-tu-de-fang-fa" class="header-anchor">#</a></h5><p>为了获取3D点云中潜在的形状和几何结构，一些方法使用了图神经网络（graph networks）。</p><p>[182]将点云看做是一些相连的简单形状和超点(Superpoint)的集合，并且使用属性有向图(attributed directed graph)（即超点图 superpoint graph ）获取结构和环境信息。接着，将大规模的点云分割问题分成三个子问题，即，geometrically homogeneous partition（几何均匀划分）, superpoint embedding（超点嵌入） and contextual segmentation（上下文分割）. </p><p>为了进一步提升，[183]提出了有监督的框架，来 oversegment a point cloud into pure superpoints（将点云过度分割为纯超点）。</p><p>为了更好地获取高维空间中的局部几何关系，[191]提出了基于Graph Embedding Module(GEM) 和 Pyramid Attention Network(PAN)的网络PyramNet。GEM模块将点云表述为有向无环图，并且在构建相似度矩阵时，利用协方差矩阵代替欧式距离。在PAN模块中，使用4个不同尺寸的卷积核来提取特征。</p><p>在[184]中，提出Graph Attention Convolution 用来从局部相邻集合中有选择性地学习相关特征。</p><h3><span id="4-2-instance-segmentation-shi-li-fen-ge">4.2 Instance Segmentation 实例分割</span><a href="#4-2-instance-segmentation-shi-li-fen-ge" class="header-anchor">#</a></h3><p>与语义分割  semantic segmentation 相比，实例分割更具有挑战性因为它需要更准确和更小的细粒度，具体而言，他不仅需要将有着不同语义的点分辨出来，还需要将有着相同语义的实例 (instance )分出来。总体而言，目前的方法可分为两个方向：<u>基于候选框的方法</u>(proposal-based)以及<u>不需要候选框的方法</u>(proposal-free)。一些里程碑式的方法具体见下图。</p><p>(按时间顺序概述了典型的三维点云实例分割方法)</p><p><img src="/2020/04/30/3D%20Point%20Clouds/is.png" alt="is" style="zoom: 50%;"></p><h4><span id="4-2-1-proposal-based-methods-ji-yu-hou-xuan-kuang">4.2.1 Proposal-based Methods 基于候选框</span><a href="#4-2-1-proposal-based-methods-ji-yu-hou-xuan-kuang" class="header-anchor">#</a></h4><p>这类方法将实例分割问题分成两个子任务：3D物体检测（3D object detection ）和实例mask的预测（instance mask prediction）。</p><p>[192]提出了3D fully-convolutional Semantic Instance Segmentation (3D-SIS) network，来实现在RGB-D数据上的语义实例分割。该网络从颜色和几何中学习特征。与3D object detection 类似，3D Region Proposal Network（3D-RPN）和 3D ROI layer用来预测bounding box的位置，物体类别和instance mask。</p><p>根据合成分析策略，[193]提出了Generative Shape Proposal Network(GSPN)来产生3D候选框。这些候选框再通过R-PointNet修正。最终的标签通过预测各个点的二进制mask来得到。与直接从点云数据回归三维边界框不同，该方法通过加强几何理解，去除了大量无用的候选框。</p><p>通过将2D全景分割( 2D panoptic segmentation)扩展到3D映射，[194]为实现大规模三维重建（3D reconstruction）、语义标注（semantic labeling）和instance segmentation，提出了一种在线三维映射系统（oneline volumetirc 3D mapping system）。该方法首先利用2D语义和实例分割网络来获得像素级的全景标签（panoptic labels ），然后将这些标签整合到 volumtric map 上。进一步使用全连接的CRF来实现准确的分割，该语义映射系统能够实现高质量的语义映射（ semantic mapping）和具有判别性的目标检测（object recognition）。</p><p>[195]提出了单阶段的，不需要anchor的端到端可训练网络—3D-BoNet，来实现点云上的 instance segmentation。该方法对所有可能的instance 直接回归大致的3D bounding boxes，接着利用点级别的二分类器（binary classifier）来获取实例标签。特别地，该 bounding box generation task是被当做是最优分配问题。同时，使用了multi-criteria 损失函数来正则化生成的bounding boxes。该方法不需要任何的后处理操作，并且有很高的计算效率。</p><p>[196]提出了针对大规模户外LiDAR点云进行instance segmentation的网络。该方法使用self-attention blocks，在点云的鸟瞰图上学习特征表示（feature representation），根据预测的水平中心和高度限制获得最终实例标签（instance labels）。</p><p>总的来说，基于候选框的方法较为直观，并且实例分割的结果通常较好。然而该方法需要多阶段的训练并且需要对多余候选框进行裁剪。因此通常都需要更多的时间和计算资源。</p><h4><span id="4-2-2-proposal-free-methods-bu-xu-yao-hou-xuan-kuang">4.2.2 Proposal-free Methods 不需要候选框</span><a href="#4-2-2-proposal-free-methods-bu-xu-yao-hou-xuan-kuang" class="header-anchor">#</a></h4><p>不需要候选框的方法[197-202]并没有目标检测的模块（ object detection module）。作为替代的是，他们通常将instance segmentation 认为是semantic segmentation （语义分割）后的聚类步骤。具体而言，需要现有的方法都基于这样的假设：属于同一实例的点应当有着相似的特征。因此这类方法通常聚焦于判别式的特征学习（discriminative feature learning）和点云聚类（point grouping）。</p><p>……</p><p>总体而言，不需要候选框的方法不需要耗费资源的区域生成步骤。然而，因为该方法不检测物体的边界，导致该方法的准确率较低。</p><h3><span id="4-3-part-segmentation">4.3 Part Segmentation</span><a href="#4-3-part-segmentation" class="header-anchor">#</a></h3><p>零件分割（part segmentation of 3D shapes）的主要困难来自于两方面。第一，有相同语义标签（ semantic label）的部件（shape parts）有着较大的几何变化和不确定性；第二，该方法需要对噪声和采样具有鲁棒性。</p><p>[208]提出了VoxSegNet，在3D体素数据上来实现细粒度的零件分割。</p><p>[209]将FCN与surface-based CRF组合，实现端到端的3D 零件分割。他们首先从不同的视角产生图像来实现optimal surface coverage，并将这些图片送入至2D网络产生置信图。接着，使用surface-based CRF 将置信图集成起来，用来对整个场景打标签。</p><p>[210]引入了Synchronized Spectral CNN(SyncSpecCNN)，在不规则非同构形状图上实现卷积。</p><p>[211]通过引入Shape Fully Convolutional Networks(SFCN),在3D网格上实现了形状分割，并且将三种低层次的几何特征作为输入。接着利用基于投票的多标签graph cut来修正分割结果。</p><p>[212]提出了弱监督的CoSegNet进行3D形状分割。该网络将一些未分割的3D点云形状作为输入，接着通过最小化group consistency loss，产生形状零件的标签。与CRF类似，预训练的part-refinement网络用来修正并且去噪。</p><p>[213]提出了Branched Auto-encoder network(BAE-NET)用来unsupervised ，one-shot和weakly supervised  3D shape co-segmentation。</p><h3><span id="4-4-summary">4.4 Summary</span><a href="#4-4-summary" class="header-anchor">#</a></h3><p>下表展示了已有方法在公开数据集上的结果，包括：S3DIS[176], Semantic3D[9], ScanNet[102]和SemanticKITTI[177].</p><p><img src="/2020/04/30/3D%20Point%20Clouds/ps.png" alt="ps" style="zoom: 50%;"></p><p>接下来这些问题需要进一步的探索。</p><ul><li>Point-based networks 是最常见的方法。然而，点的表示通常没有明确的邻域信息，现有的大多数基于点的方法不得不求助于昂贵的邻域搜索机制（KNN, ball query）。这自然地限制了这类方法的有效性，因为邻域查找方法需要很高的计算资源和内存。</li><li>在 point cloud segmentation 中，从不平衡的数据中学习仍然是具有挑战性的问题。尽管许多方法[42], [170], [182]达到了不错的结果，但性能在较小类别的数据上仍然较差。</li><li>大多数的方法[5], [27], [52], [170], [171]在较少点的点云上进行（4096）。实际上，从深度sensor上得到的点云是非常稠密的。因此需要寻求处理大规模点云的有效分割方法。</li><li>一些工作[145], [146], [167]开始在动态点云中学习空间-时间的信息，期望时空信息能够帮助提高后续任务（如3D对象识别[3D object recognition]、分割[segmentation]和补全[completion]）的性能。</li></ul><h2><span id="5-conclusion">5、CONCLUSION</span><a href="#5-conclusion" class="header-anchor">#</a></h2><p>本文章提出了当前针对3D understanding的一些SOTA方法，包括3D shape classification ，3D object detection &amp; tracking以及3D scene and object segmentation。对这些方法进行了全面的分类和性能比较。文中还介绍了各种方法的优缺点，并指出了可能的研究方向。</p><p>参考：</p><p><a href="https://zhuanlan.zhihu.com/p/103640399" target="_blank" rel="noopener">1</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;三维点云深度学习研究综述&quot;&gt;&lt;a href=&quot;#三维点云深度学习研究综述&quot; class=&quot;headerlink&quot; title=&quot;三维点云深度学习研究综述&quot;&gt;&lt;/a&gt;三维点云深度学习研究综述&lt;/h1&gt;&lt;p&gt;论文：Deep Learning for 3D Point Clouds: A Survey&lt;/p&gt;
&lt;p&gt;作者：Yulan Guo&lt;/p&gt;
&lt;p&gt;时间：2019-12&lt;/p&gt;
&lt;h2 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;动机&lt;/strong&gt;：Point cloud learning （点云学习）由于在视觉、自动驾驶、机器人等方面的广泛应用，近年来受到了广泛的关注。最近，随着点云的深度学习变得更加兴旺，人们提出了许多方法来解决这一领域的不同问题。为了促进未来的研究，本文对点云深度学习方法的最新进展进行了全面的综述。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="paper" scheme="https://sunxiaojie99.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>pytorch help</title>
    <link href="https://sunxiaojie99.github.io/2020/04/21/pytorch_help/"/>
    <id>https://sunxiaojie99.github.io/2020/04/21/pytorch_help/</id>
    <published>2020-04-21T14:03:52.000Z</published>
    <updated>2020-05-15T02:54:43.488Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="pytorch-su-cha-shou-ce">Pytorch 速查手册</span><a href="#pytorch-su-cha-shou-ce" class="header-anchor">#</a></h1><p>希望整理曾经不懂的Pytorch用法，在以后以快速得到结果</p><a id="more"></a><h2><span id="1-guan-yu-tensors">1 关于Tensors</span><a href="#1-guan-yu-tensors" class="header-anchor">#</a></h2><p><strong>自我介绍</strong>：张量的英文是Tensor，它是PyTorch里面基础的运算单位，与Numpy的ndarray相同都表示的是一个多维的矩阵。 与ndarray的最大区别就是，PyTorch的Tensor<strong>可以在 GPU 上运行</strong>，而 numpy 的 ndarray 只能在 CPU 上运行，在GPU上运行大大加快了运算速度。</p><p>在同构的意义下，<strong>第零阶张量</strong> （r = 0） 为<strong>标量</strong> （Scalar），在同构的意义下， （r = 1） 为<strong>向量</strong> （Vector）， <strong>第二阶张量</strong> （r = 2） 则称为<strong>矩阵</strong> （Matrix）<strong>，第三阶以上</strong>的统称为<strong>多维张量</strong>。</p><ol><li><strong>torch.empty()</strong>：构造一个不初始化的张量 <code>x = torch.empty(5,3)</code></li><li><strong>torch.rand()</strong>：返回一个张量，包含了从区间[0, 1)的均匀分布中抽取的一组随机数  <code>x = torch.rand(5,3)</code> 5行3列的的矩阵</li><li><strong>x.shape</strong>：可以使用与numpy相同的shape查看张量大小 <code>print(x.shape)</code> torch.Size([2, 3])</li><li><strong>size()</strong>：使用size()函数，效果与shape相同 <code>x.size()</code>  torch.Size([2, 3])</li><li><strong>torch.zeros()</strong> ：构造全0矩阵 <code>x = torch.zeros(5, 3, dtype=torch.long)</code></li><li><strong>torch.ones()</strong>：返回一个张量，全1 <code>x = torch.ones(2, 2)</code></li><li><strong>torch.eye()</strong>：初始化一个单位矩阵，即对角线为1 其他为0，<code>eye=torch.eye(2,2)</code></li><li><strong>torch.randn()</strong>：返回一个张量，包含了从标准正态分布（均值为0，方差为1，即高斯白噪声）中抽取的一组随机数。<code>torch.randn(2, 3)</code></li><li><strong>torch.linspace(start, end, steps=100, out=None)</strong> → Tensor：返回一个1维张量，包含在区间start和end上均匀间隔的step个点。</li><li><strong>torch.tensor()</strong>：构造一个张量，直接使用数据 <code>x = torch.tensor([5.5, 3])</code></li><li><strong>x.new_ones()</strong>：基于已经存在的tensor创建一个张量 <code>x = x.new_ones(5, 3, dtype=torch.double)</code></li><li><strong>torch.randn_like()</strong>：<code>x = torch.randn_like(x, dtype=torch.float)</code> 会覆盖了以前的类型</li><li><strong>torch.size()</strong>：获取tensor的维度信息, torch.Size 是一个元组，所以它支持左右的元组操作。 <code>x.size()</code></li><li><strong>x + y</strong>：加法</li><li><strong>torch.add(x, y)</strong>：加法</li><li><strong>torch.add(x, y, out=result)</strong>：加法，结果赋给result <code>result = torch.empty(5, 3)</code></li><li><strong>y.add_(x)</strong>：把x加到y上面，直接覆盖y原来的值，<strong>以_为结尾的函数，均会改变调用值</strong>。</li><li><strong>x[:, 1]</strong>：输出第二列，注意索引从0开始</li><li><strong>torch.view</strong>()：改变一个tensor的大小或者性质<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>,<span class="number">4</span>)  <span class="comment"># torch.Size([4, 4])</span></span><br><span class="line">y = x.view(<span class="number">16</span>) <span class="comment"># 16维的一个list，不是矩阵了 torch.Size([16])</span></span><br><span class="line">z = x.view(<span class="number">-1</span>, <span class="number">8</span>) <span class="comment"># the size -1 is inferred from other dimensions  torch.Size([2, 8]</span></span><br></pre></td></tr></table></figure></li><li><strong>a.transpose(1, 2)</strong>：Swaps 2nd and 3rd dimension</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>) <span class="comment"># torch.Size([1, 2, 3, 4])</span></span><br><span class="line">b = a.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># torch.Size([1, 3, 2, 4])</span></span><br></pre></td></tr></table></figure><ol><li><strong>x.item()</strong>：对于标量（零阶张量），我们可以直接使用 .item() 从中取出其对应的python对象的数值；特别的：如果张量中只有一个元素的tensor也可以调用<code>tensor.item</code>方法。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标量</span></span><br><span class="line">scalar =torch.tensor(<span class="number">3.1433223</span>)</span><br><span class="line">print(scalar) <span class="comment"># tensor(3.1433)</span></span><br><span class="line">scalar.size() <span class="comment"># torch.Size([])</span></span><br><span class="line">scalar.item() <span class="comment"># 3.143322229385376</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 只有一个元素的tensor，使用.item()来获得这个的value。</span></span><br><span class="line">x = torch.randn(<span class="number">1</span>)</span><br><span class="line">print(x) <span class="comment"># tensor([-1.7860])</span></span><br><span class="line">print(x.item()) <span class="comment"># -1.7859678268432617</span></span><br><span class="line">print(x.size()) <span class="comment"># torch.Size([1])</span></span><br><span class="line"></span><br><span class="line">loss = (y_pred - y).pow(<span class="number">2</span>).sum().item()</span><br></pre></td></tr></table></figure><ol><li><p><strong>x.mm(y)</strong>：张量相乘（numpy中的x.dot(y)）</p></li><li><p><strong>x.t()</strong>：张量转置（numpy 中的x.T）</p></li><li><p><strong>x.clamp(min=0)</strong>：relu函数（numpy 中的np.maximum(h, 0)）</p></li><li><p><strong>x.clone()</strong>：张量复制（numpy 中的x.copy() ）</p></li><li><p><strong>.pow(2)</strong>：每个元素平方 <code>loss = (y_pred - y).pow(2).sum()</code></p></li><li><p><strong>数据类型</strong>：Tensor的基本数据类型有五种</p><ul><li>32位浮点型：torch.FloatTensor。 (默认) <code>tensor.float()</code></li><li>64位整型：torch.LongTensor。 <code>tensor.long()</code></li><li>32位整型：torch.IntTensor。<code>tensor.int()</code></li><li>16位整型：torch.ShortTensor。 <code>tensor.short()</code></li><li>64位浮点型：torch.DoubleTensor。</li><li>除以上数字类型外，还有 byte和chart型 <code>tensor.char()</code> <code>tensor.byte()</code></li></ul></li><li><p><strong>numpy和Tensor转换</strong>：</p><ul><li>```python<br>a = torch.randn((3, 2))<h1><span id="tensor-zhuan-hua-wei-numpy">tensor转化为numpy</span><a href="#tensor-zhuan-hua-wei-numpy" class="header-anchor">#</a></h1>numpy_a = a.numpy()<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- &#96;&#96;&#96;python</span><br><span class="line">  # numpy转化为Tensor</span><br><span class="line">  torch_a &#x3D; torch.from_numpy(numpy_a)</span><br><span class="line">  torch_a</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>torch.max()</strong>：eg：dim=1代表沿着行取最大值，<code>max_value, max_idx = torch.max(x, dim=1)</code></p></li><li><p><strong>torch.sum()</strong>：eg：每行 x 求和，<code>sum_x = torch.sum(x, dim=1)</code></p></li></ol><h2><span id="2-qiu-dao-xiang-guan">2 求导相关</span><a href="#2-qiu-dao-xiang-guan" class="header-anchor">#</a></h2><ol><li><p><strong>requires_grad=False</strong>：在张量创建时，通过设置 requires_grad 标识为Ture来告诉Pytorch需要对该张量进行自动求导，PyTorch会记录该张量的每一步操作历史并自动计算。<strong>默认为False</strong>，如果我们想计算某些的tensor的梯度，我们只需要在建立这个tensor时加入这么一句：requires_grad=True。<code>x = torch.rand(5, 5, requires_grad=True)</code></p></li><li><p><strong>x.grad</strong>：如果这个tensor x的requires_grad=True，那么反向传播之后x关于某个标量值的梯度会累积在张量 x.grad上。PyTorch会自动追踪和记录对与张量的所有操作，当计算完成后调用.backward()方法自动计算梯度并且将计算结果保存到grad属性中。</p></li><li><p><strong>.grad_fn</strong>：在张量进行操作后，grad_fn会被赋予一个新的函数，这个函数引用了一个创建了这个Tensor类的Function对象。 Tensor和Function互相连接生成了一个非循环图，它记录并且编码了完整的计算历史。每个张量都有一个.grad_fn属性，如果这个张量是用户手动创建的那么这个张量的grad_fn是None。</p></li><li><p><strong>with torch.no_grad():</strong>：在训练神经网络时，我们通常不希望通过权重更新步骤进行反向传播，使用<code>with torch.no_grad():</code>上下文管理器来防止构造计算图。使用上下文管理器临时禁止对已设置requires_grad=True的张量进行自动求导。这个方法<strong>在测试集计算准确率</strong>的时候会经常用到。使用.no_grad()进行嵌套后，代码不会跟踪历史记录，也就是说保存的这部分记录会减少内存的使用量并且会加快少许的运算速度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w1 -= learning_rate * w1.grad</span><br><span class="line">        w2 -= learning_rate * w2.grad</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 反向传播后手动将梯度设置为零</span></span><br><span class="line">        w1.grad.zero_()</span><br><span class="line">        w2.grad.zero_()</span><br></pre></td></tr></table></figure></li><li><p><strong>with torch.set_grad_enabled(False)</strong>：一个全局的环境，接下来所有的tensor运算产生的新的节点都是不可求导的；设置为True就是可以求导的了</p></li><li><p><strong>loss.backward()</strong>：.backward() 自动计算所有的requires_grad=True 张量的梯度，张量的梯度将累积到其<code>.grad</code>属性中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">z=torch.sum(x+y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果Tensor类表示的是一个标量（即它包含一个元素的张量），则不需要为backward()指定任何参数，但是如果它有更多的元素，则需要指定一个gradient参数，它是形状匹配的张量。 以上的 z.backward()相当于是z.backward(torch.tensor(1.))的简写。 这种参数常出现在图像分类中的单标签分类，输出一个标量代表图像的标签。</span></span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = torch.rand(<span class="number">5</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">z= x**<span class="number">2</span>+y**<span class="number">3</span></span><br><span class="line"><span class="comment">#我们的返回值不是一个标量，所以需要输入一个大小相同的张量作为参数，这里我们用ones_like函数根据x生成一个张量</span></span><br><span class="line">z.backward(torch.ones_like(x))</span><br><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure></li><li><p><strong>↑Autograd 过程解析</strong>：Python的 <code>dir()</code> 返回参数的属性、方法列表。<code>z</code>是一个Tensor变量，看看里面有哪些成员变量。我们直接排除掉一些Python中特殊方法（以_开头和结束的）和私有方法（以<em>开头的，直接看几个比较主要的属性： <code>.is_leaf</code>：记录是否是叶子节点。通过这个属性来确定这个变量的类型，在官方文档中所说的“graph leaves”，“leaf variables”，都是指像<code>x</code>，<code>y</code>这样的手动创建的、而非运算得到的变量，这些变量成为<strong>创建变量</strong>。 像<code>z</code>这样的，是通过计算后得到的结果称为<em>*结果变量</em></em>。</p></li><li><p><strong>.is_leaf</strong>：一个变量是创建变量还是结果变量是通过<code>.is_leaf</code>来获取的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = torch.rand(<span class="number">5</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">z= x**<span class="number">2</span>+y**<span class="number">3</span></span><br><span class="line">print(<span class="string">"x.is_leaf="</span>+str(x.is_leaf)) <span class="comment"># x.is_leaf=True</span></span><br><span class="line">print(<span class="string">"z.is_leaf="</span>+str(z.is_leaf)) <span class="comment"># z.is_leaf=False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># x是手动创建的没有通过计算，所以他被认为是一个叶子节点也就是一个创建变量，而z是通过x与y的一系列计算得到的，所以不是叶子结点也就是结果变量。</span></span><br></pre></td></tr></table></figure></li><li><p><strong>为什么我们执行<code>z.backward()</code>方法会更新<code>x.grad</code>和<code>y.grad</code>呢？</strong></p><ul><li><p><code>.grad_fn</code>属性记录的就是这部分的操作，记录并且编码了完整的计算历史。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">z.grad_fn  <span class="comment"># &lt;AddBackward0 at 0x120840a90&gt;</span></span><br><span class="line"><span class="comment"># grad_fn是一个AddBackward0类型的变量</span></span><br></pre></td></tr></table></figure></li><li><p>我们 dir(z.grad_fn)，看看里面有什么东西？<code>next_functions</code> 就是<code>grad_fn</code>的精华！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dir(z.grad_fn) <span class="comment"># 'next_functions',</span></span><br><span class="line">z.grad_fn.next_functions </span><br><span class="line"><span class="comment"># ((&lt;PowBackward0 at 0x1208409b0&gt;, 0), (&lt;PowBackward0 at 0x1208408d0&gt;, 0))</span></span><br><span class="line"><span class="comment"># next_functions是一个tuple of tuple of PowBackward0 and int。</span></span><br><span class="line"><span class="comment"># 为什么是2个tuple ？ 因为我们的操作是z= x**2+y**3 刚才的AddBackward0是相加，而前面的操作是乘方 PowBackward0。tuple第一个元素就是x相关的操作记录</span></span><br></pre></td></tr></table></figure></li><li><p>继续挖掘：在PyTorch的反向图计算中，<code>AccumulateGrad</code>类型代表的就是叶子节点类型，也就是计算图终止节点。<code>AccumulateGrad</code>类中有一个<code>.variable</code>属性指向叶子节点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">xg = z.grad_fn.next_functions[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">dir(xg) <span class="comment"># next_functions</span></span><br><span class="line">x_leaf=xg.next_functions[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">type(x_leaf) <span class="comment"># AccumulateGrad</span></span><br><span class="line"></span><br><span class="line">x_leaf.variable <span class="comment"># 这个.variable的属性就是我们的生成的变量x</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"x_leaf.variable的id:"</span>+str(id(x_leaf.variable)))</span><br><span class="line">print(<span class="string">"x的id:"</span>+str(id(x)))</span><br><span class="line"><span class="comment"># x_leaf.variable的id:4840553424</span></span><br><span class="line"><span class="comment"># x的id:4840553424</span></span><br></pre></td></tr></table></figure></li><li><p>这样整个规程就很清晰了：</p><ul><li>当我们执行z.backward()的时候。这个操作将调用z里面的grad_fn这个属性，执行求导的操作。</li><li>这个操作将遍历grad_fn的next_functions，然后分别取出里面的Function（AccumulateGrad），执行求导操作。这部分是一个递归的过程直到最后类型为叶子节点。</li><li>计算出结果以后，将结果保存到他们对应的variable 这个变量所引用的对象（x和y）的 grad这个属性里面。</li><li>求导结束。所有的叶节点的grad变量都得到了相应的更新</li></ul></li></ul></li><li><p><strong>.detach()</strong>：停止tensor历史记录的跟踪，该tensor与计算历史记录分离，并防止将来的计算被跟踪。</p></li><li><p><strong>.grad.zero_()</strong>：将梯度设置为零 <code>w1.grad.zero_()</code></p></li><li><p><strong>.zero_grad()</strong>：手动将梯度缓冲区设置为零 <code>optimizer.zero_grad()</code></p></li><li><p><strong>torch.device()</strong>：应该是方便GPU上运行的 <code>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)</code></p></li><li><p><strong>torch.autograd.Function</strong>：<strong>如果需要自定义autograd扩展新的功能</strong>，就需要扩展Function类。因为Function使用autograd来计算结果和梯度，并对操作历史进行编码。定义<code>torch.autograd.Function</code>的子类并三个方法，来<strong>定义自己的自动求导运算</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># __init__ (optional)：如果这个操作需要额外的参数则需要定义这个Function的构造函数，不需要的话可以忽略。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># forward()：执行前向传播的计算代码</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># backward()：反向传播时梯度计算的代码。 参数的个数和forward返回值的个数一样，每个参数代表传回到此操作的梯度。</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用 MyReLU.apply 函数来使用自定义的ReLU</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyReLU</span><span class="params">(torch.autograd.Function)</span>:</span></span><br><span class="line">   </span><br><span class="line"><span class="comment"># (输入参数是张量)</span></span><br><span class="line">    <span class="comment"># 方法必须是静态方法，所以要加上@staticmethod </span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(ctx, x)</span>:</span></span><br><span class="line">         <span class="comment"># ctx 用来保存信息这里类似self，并且ctx的属性可以在backward中调用</span></span><br><span class="line">        ctx.save_for_backward(x)</span><br><span class="line">        <span class="keyword">return</span> x.clamp(min=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(ctx, grad_output)</span>:</span></span><br><span class="line">        x, = ctx.saved_tensors</span><br><span class="line">        grad_x = grad_output.clone()</span><br><span class="line">        grad_x[x &lt; <span class="number">0</span>] =<span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> grad_x</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 详见 大刀阔斧，步步推进 </span></span><br><span class="line"><span class="comment"># 调用 MyReLU.apply 函数来使用自定义的ReLU</span></span><br><span class="line">y_pred = MyReLU.apply(x.mm(w1)).mm(w2)</span><br></pre></td></tr></table></figure></li><li><h2><span id="3-shu-ju-jia-zai-chu-li-xiang-guan">3 数据加载处理相关</span><a href="#3-shu-ju-jia-zai-chu-li-xiang-guan" class="header-anchor">#</a></h2></li></ol><p><strong>相关头文件</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function, division</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd              <span class="comment">#用于更容易地进行csv解析</span></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io, transform    <span class="comment">#用于图像的IO和变换</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, utils</span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略警告</span></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"> </span><br><span class="line">plt.ion()   <span class="comment"># interactive mode 在脚本中遇到plt.show()，代码还是会继续执行</span></span><br></pre></td></tr></table></figure><ol><li><p><strong>pd.read_csv()</strong>：读取csv数据 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">landmarks_frame = pd.read_csv(<span class="string">'data/faces/face_landmarks.csv'</span>)</span><br><span class="line">n = <span class="number">65</span></span><br><span class="line">img_name = landmarks_frame.iloc[n, <span class="number">0</span>] <span class="comment"># 获取第65行第0列数据</span></span><br><span class="line"></span><br><span class="line">landmarks = landmarks_frame.iloc[n, <span class="number">1</span>:].as_matrix() <span class="comment"># 将第1列以后的转化为矩阵</span></span><br><span class="line">landmarks = landmarks.astype(<span class="string">'float'</span>).reshape(<span class="number">-1</span>, <span class="number">2</span>)  <span class="comment"># 将原本一行的数据转化为两行列，一列为x坐标，y坐标</span></span><br></pre></td></tr></table></figure></li><li><p><strong>.iloc[n, 1:]</strong>：数据切片，获取第n行，第1列以后的数据</p></li><li><p><strong>.as_matrix()</strong>：转化为矩阵</p></li><li><p><strong>.astype(‘float’)</strong>：转换格式</p></li><li><p><strong>.reshape(-1, 2)</strong>：重塑大小</p></li><li><p><strong>torch.utils.data.Dataset</strong>：表示数据集的抽象类，因此自定义的数据集应继承Dataset 并重载以下方法</p><ul><li><p><code>__len__</code> ：实现 <code>len(dataset)</code> 返回数据集的尺寸</p><ul><li><code>__getitem__</code>：用索引(<code>0</code> 到 <code>len(self)</code>)获取一条数据或一个样本</li><li><code>__init__</code>：读取csv的文件内容</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FaceLandmarksDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, csv_file, root_dir, transform=None)</span>:</span></span><br><span class="line">        self.landmarks_frame = pd.read_csv(csv_file)</span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.transform = transform</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.landmarks_frame) <span class="comment"># 有多少样本（行）</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[index, <span class="number">0</span>])</span><br><span class="line">        image = io.imread(img_name)</span><br><span class="line">        landmarks = self.landmarks_frame.iloc[index, <span class="number">1</span>:]</span><br><span class="line">        landmarks = np.array([landmarks])</span><br><span class="line">        landmarks = landmarks.astype(<span class="string">'float'</span>).reshape(<span class="number">-1</span>, <span class="number">2</span>)</span><br><span class="line">        sample = &#123;<span class="string">'image'</span>: image, <span class="string">'landmarks'</span>: landmarks&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            sample = self.transform(sample)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> sample</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>torchvision.transforms.Compose</strong>：组合一个变换</p></li></ol><ul><li>Resize：把给定的图片resize到given size</li><li>transforms.ToTensor(), convert a PIL image to tensor <code>(H*W*C)</code> in range [0,255] to a torch.Tensor<code>(C*H*W)</code> in the range [0.0,1.0]  把[0,255]转换到[0.0, 1.0]</li><li>transforms.Normalize ：Normalized an tensor image with mean and standard deviation; </li><li>ToPILImage: convert a tensor to PIL image</li><li>Scale：目前已经不用了，推荐用Resize</li><li>CenterCrop：在图片的中间区域进行裁剪</li><li>RandomCrop：在一个随机的位置进行裁剪</li><li>RandomHorizontalFlip：以0.5的概率水平翻转给定的PIL图像</li><li>RandomVerticalFlip：以0.5的概率竖直翻转给定的PIL图像</li><li>RandomResizedCrop：将PIL图像裁剪成任意大小和纵横比</li><li>Grayscale：将图像转换为灰度图像</li><li>RandomGrayscale：将图像以一定的概率转换为灰度图像</li><li><p>ColorJitter：随机改变图像的亮度对比度和饱和度。</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets</span><br><span class="line"></span><br><span class="line">data_transform = transforms.Compose([</span><br><span class="line">        transforms.RandomSizedCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                             std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ])</span><br><span class="line">hymenoptera_dataset = datasets.ImageFolder(root=<span class="string">'hymenoptera_data/train'</span>, transform=data_transform)</span><br><span class="line">dataset_loader = torch.utils.data.DataLoader(hymenoptera_dataset,batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>,num_workers=<span class="number">4</span>)</span><br></pre></td></tr></table></figure></li></ul><ol><li><p><strong>np.random.randint(0,n)</strong>：获取一个随机整数</p></li><li><p><strong>torch.utils.data.DataLoader</strong>：对所有数据集简单的使用for循环牺牲了许多功能，尤其是：批量处理数据、打乱数据。torch.utils.data.DataLoader是一个提供上述所有这些功能的迭代器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 代码一般是这么写的：</span></span><br><span class="line"><span class="comment"># 1. 定义学习集 DataLoader</span></span><br><span class="line">train_data = torch.utils.data.DataLoader(hymenoptera_dataset,batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>,num_workers=<span class="number">4</span>,各种设置...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.将数据喂入神经网络进行训练</span></span><br><span class="line"><span class="keyword">for</span> i, (input, target) <span class="keyword">in</span> enumerate(train_data): </span><br><span class="line">    循环代码行......</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataLoader中的几个重要参数</span></span><br><span class="line"><span class="comment"># dataset：（数据类型 dataset）输入的数据类型</span></span><br><span class="line"><span class="comment"># batch_size：（数据类型 int）每次输入数据的行数，默认为1,每次喂给神经网络多少行数据</span></span><br><span class="line"><span class="comment"># shuffle：（数据类型 bool）洗牌。默认设置为False。在每次迭代训练时是否将数据洗牌，默认设置是False。将输入数据的顺序打乱，是为了使数据更有独立性，但如果数据是有序列特征的，就不要设置成True了。</span></span><br><span class="line"><span class="comment"># num_workers：（数据类型 Int）工作者数量，默认是0。使用多少个子进程来导入数据。设置为0，就是使用主进程来导入数据。注意：这个数字必须是大于等于0的，负数估计会出错。</span></span><br><span class="line"><span class="comment"># drop_last：（数据类型 bool）丢弃最后数据，默认为False。设置了 batch_size 的数目后，最后一批数据未必是设置的数目，有可能会小些。这时你是否需要丢弃这批数据。</span></span><br><span class="line"><span class="comment"># timeout：（数据类型 numeric）超时，默认为0。是用来设置数据读取的超时时间的，但超过这个时间还没读取到数据的话就会报错。 所以，数值必须大于等于0。</span></span><br></pre></td></tr></table></figure><ul><li><p>DataLoader返回的是一个可迭代对象，我们可以使用迭代器分次获取数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dl = torch.utils.data.DataLoader(ds_demo, batch_size=<span class="number">10</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">idata=iter(dl)</span><br><span class="line">print(next(idata))</span><br></pre></td></tr></table></figure></li><li><p>常见的用法是使用for循环对其进行遍历</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(dl):</span><br><span class="line">    print(i,data)</span><br><span class="line">    <span class="comment"># 为了节约空间，这里只循环一遍</span></span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure></li><li><p>我们已经可以<strong>通过dataset定义数据集</strong>，并<strong>使用Datalorder载入和遍历数据集</strong>，除了这些以外，PyTorch还提供能<strong>torcvision的计算机视觉扩展包</strong>，torchvision 是PyTorch中专门用来<strong>处理图像的库</strong>，里面封装了torchvision.datasets、torchvision.models、torchvision.transforms：</p><ul><li><p><strong>torchvision.datasets</strong>：torchvision.datasets 可以理解为PyTorch团队自定义的dataset，这些dataset帮我们提前处理好了很多的图片数据集，我们拿来就可以直接使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">MNIST</span><br><span class="line">COCO</span><br><span class="line">Captions</span><br><span class="line">Detection</span><br><span class="line">LSUN</span><br><span class="line">ImageFolder</span><br><span class="line">Imagenet<span class="number">-12</span></span><br><span class="line">CIFAR</span><br><span class="line">STL10</span><br><span class="line">SVHN</span><br><span class="line">PhotoTour </span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例如下：</span></span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets</span><br><span class="line">trainset = datasets.MNIST(root=<span class="string">'./data'</span>, <span class="comment"># 表示 MNIST 数据的加载的目录</span></span><br><span class="line">                                      train=<span class="literal">True</span>,  <span class="comment"># 表示是否加载数据库的训练集，false的时候加载测试集</span></span><br><span class="line">                                      download=<span class="literal">True</span>, <span class="comment"># 表示是否自动下载 MNIST 数据集</span></span><br><span class="line">                                      transform=<span class="literal">None</span>) <span class="comment"># 表示是否需要对数据进行预处理，none为不进行预处理</span></span><br></pre></td></tr></table></figure></li><li><p><strong>torchvision.models</strong>：torchvision不仅提供了常用图片数据集，还提供了训练好的模型，可以加载之后，直接使用，或者在进行迁移学习。 torchvision.models模块的子模块中包含以下模型结构。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">AlexNet</span><br><span class="line">VGG</span><br><span class="line">ResNet</span><br><span class="line">SqueezeNet</span><br><span class="line">DenseNet</span><br><span class="line"></span><br><span class="line"><span class="comment">#我们直接可以使用训练好的模型，当然这个与datasets相同，都是需要从服务器下载的</span></span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line">resnet18 = models.resnet18(pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li><li><p><strong>torchvision.transforms</strong>：transforms 模块提供了一般的图像转换操作类，用作数据处理和数据增强</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">as</span> transforms</span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.RandomCrop(<span class="number">32</span>, padding=<span class="number">4</span>),  <span class="comment">#先四周填充0，在把图像随机裁剪成32*32</span></span><br><span class="line">    transforms.RandomHorizontalFlip(),  <span class="comment">#图像一半的概率翻转，一半的概率不翻转</span></span><br><span class="line">    transforms.RandomRotation((<span class="number">-45</span>,<span class="number">45</span>)), <span class="comment">#随机旋转</span></span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>), (<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>)), <span class="comment">#R,G,B每层的归一化用到的均值和方差</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>肯定有人会问：(0.485, 0.456, 0.406), (0.2023, 0.1994, 0.2010) 这几个数字是什么意思？这些都是根据ImageNet训练的归一化参数，可以直接使用，我们认为这个是固定值就可以</p></li></ul></li></ul></li><li><p><strong>torchvision.datasets.ImageFolder</strong>：torchvision包提供了常用的数据集类(datasets)和转换(transforms)，你可能不需要自己构造这些类。很常用的数据集类<strong>ImageFolder</strong>。 它假定了数据集是以如下方式构造的，其中’ants’,bees’等是分类标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root/ants/xxx.png</span><br><span class="line">root/ants/xxy.jpeg</span><br><span class="line">root/ants/xxz.png</span><br><span class="line">.</span><br><span class="line"></span><br><span class="line">root/bees/<span class="number">123.j</span>pg</span><br><span class="line">root/bees/nsdf3.png</span><br><span class="line">root/bees/asd932_.png</span><br><span class="line"></span><br><span class="line">hymenoptera_dataset = datasets.ImageFolder(root=<span class="string">'hymenoptera_data/train'</span>,</span><br><span class="line">                                           transform=data_transform)</span><br></pre></td></tr></table></figure></li><li><p><strong>torch.unsqueeze()</strong>：对<strong>数据维度进行扩充</strong>。给指定位置加上维数为一的维度，比如原本有个三行的数据（3），在0的位置加了一维就变成一行三列（1,3）</p><ul><li><code>a.unsqueeze(N)</code>： 就是在a中指定位置N加上一个维数为1的维度</li><li><code>b=torch.unsqueeze(a，N)</code>: b就是在a中指定位置N加上一个维数为1的维度</li></ul></li><li><p><strong>torch.squeeze()</strong>：对<strong>数据的维度进行压缩</strong>，去掉维数为1的的维度，比如是一行或者一列这种，一个一行三列（1,3）的数去掉第一个维数为一的维度之后就变成（3）行。</p><ul><li><code>squeeze(a)</code>:a中所有为1的维度删掉，不为1的维度没有影响。</li><li><code>a.squeeze(N)</code> :去掉a中指定的维数为一的维度</li><li><code>b=torch.squeeze(a，N)</code> a中去掉指定的定的维数为一的维度。</li></ul></li><li><p><strong>torchvision.datasets</strong>：PyTorch通过torch.utils.data对一般常用的数据加载进行了封装，可以很容易地实现多线程数据预读和批量加载。 并且torchvision已经预先实现了常用图像数据集，包括前面使用过的CIFAR-10，ImageNet、COCO、MNIST、LSUN等数据集，可通过torchvision.datasets方便的调用</p></li></ol><h2><span id="4-wang-luo-da-jian-xiang-guan">4 网络搭建相关</span><a href="#4-wang-luo-da-jian-xiang-guan" class="header-anchor">#</a></h2><ol><li><p><strong>torch.nn</strong>：计算图和autograd是十分强大的工具，可以定义复杂的操作并自动求导；然而对于大规模的网络，autograd太过于底层，nn包中定义一组大致等价于层的模块。一个模块接受输入的tesnor，计算输出的tensor，而且还保存了一些内部状态比如需要学习的tensor的参数等。nn包中也定义了一组损失函数（loss functions），用来训练神经网络。</p></li><li><p><strong>torch.nn.Sequential()</strong>：nn.Sequential是包含其他模块的模块，并按顺序应用这些模块来产生其输出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out)</span><br><span class="line">)</span><br><span class="line">y_pred = model(x) <span class="comment"># 前向传播：通过向模型传入x计算预测的y。</span></span><br><span class="line">model.zero_grad() <span class="comment"># 反向传播之前清零梯度</span></span><br></pre></td></tr></table></figure></li><li><p><strong>torch.nn.MSELoss(reduction=’sum’)</strong>：nn包还包含常用的损失函数的定义，这里使用平均平方误差(MSE)，设置<code>reduction=&#39;sum&#39;</code>，表示我们计算的是评分误差的‘和’，而不是平均值，<code>reduction=‘elementwise_mean’</code>来使用均方误差作为损失更为常见</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss_fn = torch.nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">loss = loss_fn(y_pred, y)</span><br><span class="line">loss.backward()</span><br></pre></td></tr></table></figure></li><li><p><strong>torch.nn.Linear()</strong>：线性层 <code>torch.nn.Linear(D_in, H)</code></p></li><li><p><strong>torch.nn.ReLU()</strong>：ReLu 激活函数 </p></li><li><p><strong>model.parameters()</strong>：获取2中定义模型的所有参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用梯度下降更新权重。</span></span><br><span class="line"><span class="comment"># 每个参数都是张量，更新它的数值</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">            param -= learning_rate * param.grad</span><br></pre></td></tr></table></figure></li><li><p><strong>torch.optim</strong>：SGD、AdaGrad、RMSProp、Adam等更复杂的优化器来训练神经网络。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1e-4</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在反向传播之前，使用optimizer将它要更新的所有张量的梯度清零(这些张量是模型可学习的权重)</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">loss.backward() <span class="comment"># 反向传播，根据模型参数计算loss的损失梯度</span></span><br><span class="line">optimizer.step() <span class="comment"># 调用Optimizer的step函数使它所有参数更新</span></span><br></pre></td></tr></table></figure></li><li><p><strong>torch.nn.Module</strong>：需要指定比现有模块序列更复杂的模型；对于这些情况，可以通过继承nn.Module 并定义 forward 函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, D_in, H, D_out)</span>:</span></span><br><span class="line">        super(TwoLayerNet, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(D_in, H)</span><br><span class="line">        self.linear2 = torch.nn.Linear(H, D_out)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        h_relu = self.linear1(x).clamp(min=<span class="number">0</span>)</span><br><span class="line">        y_pred = self.linear2(h_relu)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 通过实例化上面定义的类来构建我们的模型。</span></span><br><span class="line">model = TwoLayerNet(D_in, H, D_out)</span><br><span class="line">y_pred = model(x) <span class="comment"># 前向传播：通过向模型传递x计算预测值y</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 详见《神经网络》</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        <span class="comment"># 1 input image channel, 6 output channels, 5x5 square convolution</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>) <span class="comment"># 输入1个通道，输出6个通道，5×5filter</span></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>) <span class="comment"># 输入6个通道，输出16个通道，5×5filter</span></span><br><span class="line">        <span class="comment"># an affine operation: y = Wx + b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># Max pooling over a (2, 2) window</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">        <span class="comment"># If the size is a square you can only specify a single number</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(<span class="number">-1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:] <span class="comment"># all dimensions except the batch dimension</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure></li><li><p><strong>net.parameters()</strong>：返回可被学习的参数（权重）列表和值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net = Net()</span><br><span class="line">params = list(net.parameters())</span><br><span class="line">print(len(params))</span><br><span class="line">print(params[<span class="number">0</span>].size()) <span class="comment"># conv1's .weight</span></span><br></pre></td></tr></table></figure></li><li><p><strong>n.functional</strong> ：除了nn别名以外，我们还引用了nn.functional，这个包中包含了神经网络中使用的一些常用函数，这些函数的特点是，不具有可学习的参数(如ReLU，pool，DropOut等)，这些函数可以放在构造函数中，也可以不放，但是这里建议不放。<code>import torch.nn.functional as F</code></p></li><li></li></ol><h2><span id="5-hua-tu-xiang-guan">5 画图相关</span><a href="#5-hua-tu-xiang-guan" class="header-anchor">#</a></h2><p><strong>头文件</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io, transform    <span class="comment">#用于图像的IO和变换</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><ol><li><p><strong>torchvision.utils.make_grid()</strong>：将若干幅图像拼成一幅图像。其中padding的作用就是子图像与子图像之间的pad有多宽。在需要展示一批数据时很有用</p></li><li><p><strong>plt.imshow(image)</strong>：展示一张图，<code>plt.imshow(np.transpose(npimg, (1, 2, 0)))</code>  在plt.imshow的输入的是（imagesize,imagesize,channels），img的格式为（channels,imagesize,imagesize）,这两者的格式不一致，需要转换后显示，原来的1换到0的位置，原来的2换到1的位置，原来的0换到最后。</p></li><li><p><strong>plt.ion()</strong>：interactive mode 在脚本中遇到plt.show()，代码还是会继续执行</p></li><li><p><strong>matplotlib.pyplot.scatter</strong>：散点图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">matplotlib.pyplot.scatter(x, y, s=<span class="literal">None</span>, c=<span class="literal">None</span>, marker=<span class="literal">None</span>, cmap=<span class="literal">None</span>, norm=<span class="literal">None</span>, vmin=<span class="literal">None</span>, vmax=<span class="literal">None</span>, alpha=<span class="literal">None</span>, linewidths=<span class="literal">None</span>, verts=<span class="literal">None</span>, edgecolors=<span class="literal">None</span>, *, data=<span class="literal">None</span>, **kwargs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># x，y：表示的是大小为(n,)的数组，也就是我们即将绘制散点图的数据点</span></span><br><span class="line"><span class="comment"># s:是一个实数或者是一个数组大小为(n,)，这个是一个可选的参数。</span></span><br><span class="line"><span class="comment"># c:表示的是颜色，也是一个可选项。默认是蓝色'b',表示的是标记的颜色，或者可以是一个表示颜色的字符，或者是一个长度为n的表示颜色的序列等等.</span></span><br><span class="line"><span class="comment"># marker:表示的是标记的样式，默认的是'o'。</span></span><br></pre></td></tr></table></figure></li><li><p><strong>io.imread()</strong></p></li><li><p><strong>os.path.join()</strong>：<code>io.imread(os.path.join(&#39;data/faces/&#39;, img_name))</code></p></li><li><p><strong>fig = plt.figure()</strong>：一个画布</p></li><li><p><strong>ax = plt.subplot(1, 4, i + 1)</strong>：子图，1行，4列，这个是第i+1个</p></li><li><p><strong>ax.set_title</strong>(‘Sample #{}’.format(i))</p></li><li><p><strong>ax.axis(‘off’)</strong></p></li><li><p><strong>image = image.transpose((2, 0, 1))</strong>：交换颜色轴，因为numpy包的图片是: H <em> W </em> C，torch包的图片是: C <em> H </em> W</p></li><li><p><strong>plt.tight_layout()</strong>： 自动调整子图参数，使之填充整个图像区域</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 并遍历数据样本。我们将会打印出前四个例子的尺寸并展示标注的特征点。</span></span><br><span class="line">face_dataset = FaceLandmarksDataset(csv_file=<span class="string">'data/faces/face_landmarks.csv'</span>, root_dir=<span class="string">'data/faces/'</span>)</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(face_dataset)):</span><br><span class="line">    sample = face_dataset[i]</span><br><span class="line">    </span><br><span class="line">    print(i, sample[<span class="string">'image'</span>].shape, sample[<span class="string">'landmarks'</span>].shape)</span><br><span class="line">    </span><br><span class="line">    ax = plt.subplot(<span class="number">1</span>, <span class="number">4</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    ax.set_title(<span class="string">'Sample #&#123;&#125;'</span>.format(i))</span><br><span class="line">    ax.axis(<span class="string">'off'</span>)</span><br><span class="line">    show_landmarks(**sample)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">3</span>:</span><br><span class="line">        plt.show()</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure></li></ol><h2><span id="mo-xing-xiang-guan">模型相关</span><a href="#mo-xing-xiang-guan" class="header-anchor">#</a></h2><ol><li><p><strong>保存加载整个模型</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save model</span></span><br><span class="line">torch.save(model,<span class="string">'mymodel.pkl'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load model</span></span><br><span class="line">model=torch.load(<span class="string">'mymodel.pkl'</span>)</span><br></pre></td></tr></table></figure></li><li><p><strong>仅保存加载模型参数（推荐）</strong>：相比较于保存整个模型而言，仅保存模型参数的做法应该不仅节省空间，更有灵活性的优势。可以取出特定层的参数，这一点在已经训练好的模型上取与现有模型相同层的参数上应该有帮助。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save model parameters</span></span><br><span class="line">torch.save(model.state_dict(), <span class="string">'mymodel.pkl'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load save model parameters</span></span><br><span class="line">model_object.load_state_dict(torch.load(<span class="string">'mymodel.pkl'</span>))</span><br></pre></td></tr></table></figure></li><li><p><strong>加载别的模型中相同的网络参数至新的模型</strong>：用已经训练好的网络参数作为自己模型的网络权重的初始化。下面代码实现了从<code>model_from</code>到<code>model to</code>的相同网络参数的拷贝。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transfer_weights</span><span class="params">(model_from, model_to)</span>:</span></span><br><span class="line">    wf = copy.deepcopy(model_from.state_dict()) <span class="comment"># 对 model from中的模型参数的深度拷贝;</span></span><br><span class="line">    wt = model_to.state_dict() <span class="comment"># 对 model to模型参数的获取</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 如果在model to中出现的网络结构，但是在model from中没有出现，那么就拷贝一份给wf。这样做的目的是让wf扩充后的结构跟wt一样，即保留了model from中的模型参数，又将结构扩充到跟 model to的一样</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> wt.keys() :</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">not</span> k <span class="keyword">in</span> wf):      </span><br><span class="line">            wf[k] = wt[k]</span><br><span class="line">            </span><br><span class="line">    model_to.load_state_dict(wf) <span class="comment"># 通过load_state_dict函数加载我们想要的模型参数到目标模型model to中</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 以上的函数要求两个模型中如果具有相同的名字，那么对应的参数大小应该是一样的。</span></span><br></pre></td></tr></table></figure></li><li><p><a href="https://blog.csdn.net/u014380165/article/details/78525273" target="_blank" rel="noopener">https://blog.csdn.net/u014380165/article/details/78525273</a></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Pytorch-速查手册&quot;&gt;&lt;a href=&quot;#Pytorch-速查手册&quot; class=&quot;headerlink&quot; title=&quot;Pytorch 速查手册&quot;&gt;&lt;/a&gt;Pytorch 速查手册&lt;/h1&gt;&lt;p&gt;希望整理曾经不懂的Pytorch用法，在以后以快速得到结果&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="随笔" scheme="https://sunxiaojie99.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch 及其应用</title>
    <link href="https://sunxiaojie99.github.io/2020/04/21/pytorch/"/>
    <id>https://sunxiaojie99.github.io/2020/04/21/pytorch/</id>
    <published>2020-04-21T14:03:52.000Z</published>
    <updated>2020-05-15T02:54:32.350Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="pytorch-ji-qi-ying-yong">pytorch及其应用</span><a href="#pytorch-ji-qi-ying-yong" class="header-anchor">#</a></h1><p><strong>优点</strong>：</p><ol><li>支持GPU、灵活；</li><li>支持动态神经网络；</li><li>底层代码易于理解；</li><li>命令式体验；自定义扩展</li></ol><p><strong>缺点</strong>：</p><ol><li><p>对比TensorFlow，全面性不足，不支持快速傅里叶、沿维翻转张量和检查无穷与非数值张量；</p></li><li><p>针对移动端、嵌入式部署以及高性能服务器端的部署其性能表现有待提升；</p></li><li><p>因为框架较新，社区没有那么强大，在文档方面其C库大多数没有文档。</p><a id="more"></a></li></ol><h2><span id="huan-jing-pei-zhi">环境配置</span><a href="#huan-jing-pei-zhi" class="header-anchor">#</a></h2><ol><li>有关conda虚拟环境<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">conda list # 查看安装了哪些包</span><br><span class="line">conda env list # 查看当前存在哪些虚拟环境</span><br><span class="line">conda update conda # 检查更新当前conda</span><br><span class="line">python --version # 查看python版本</span><br><span class="line">conda create -n xxx python&#x3D;3.6 # xxx为自己命名的虚拟环境名称，该文件可在Anaconda安装目录 envs文件下找到</span><br><span class="line">conda create -n pytorch python&#x3D;3.6</span><br><span class="line">conda activate yorr_env_name # 激活虚拟环境</span><br><span class="line">conda install -n your_env_name [package] # 对虚拟环境安装额外的包</span><br><span class="line">deactivate # 关闭虚拟环境</span><br><span class="line">conda remove -n your_env_name --all</span><br><span class="line">conda remove --name your_env_name package_name # 删除环境中的某个包</span><br></pre></td></tr></table></figure></li><li>虚拟环境下安装 jupyter</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate pytorch</span><br><span class="line">conda install nb_conda</span><br></pre></td></tr></table></figure><ol><li>pytorch安装<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate pytorch</span><br><span class="line">conda install pytorch torchvision cpuonly -c pytorch</span><br></pre></td></tr></table></figure></li><li>离线安装（极其有用，血泪教训）<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://download.pytorch.org/whl/torch_stable.html</span></span><br><span class="line"><span class="comment"># 下载对应的whl，然后安装</span></span><br><span class="line">pip install D:\software\Anaconda3\whl_download\torch<span class="number">-1.5</span><span class="number">.0</span>+cpu-cp36-cp36m-win_amd64.whl</span><br></pre></td></tr></table></figure></li></ol><h2><span id="python-xue-xi-zhong-de-liang-da-fa-bao-han-shu">Python学习中的两大法宝函数</span><a href="#python-xue-xi-zhong-de-liang-da-fa-bao-han-shu" class="header-anchor">#</a></h2><ol><li><strong>dir() 道具</strong>：相当于你的手和眼睛，它可以帮你打开东西和看到其中的东西。能让你了解package有哪些东西，也许是更小的模块，或者是函数。dir() 函数，当输出是带有前后双下划线的，这个时候，就表明，这是一个函数，一个工具。你应该使用 help() 函数去查看这个工具的使用方法。</li><li><strong>help() 道具</strong>：相当于说明书，你可以知道每个工具的使用方法。能让你知道函数的使用方法。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">dir(torch)</span><br><span class="line">help(torch.cuda.is_available)</span><br></pre></td></tr></table></figure></li></ol><h2><span id="shu-ju">数据</span><a href="#shu-ju" class="header-anchor">#</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">img_path = <span class="string">""</span> <span class="comment"># 注意，win下\\</span></span><br><span class="line">img = Image.open(ima_path)</span><br><span class="line">img.show()</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">dir_path = <span class="string">""</span> <span class="comment"># /</span></span><br><span class="line">img_path_list = os.listdir(dir_path) <span class="comment"># 文件夹下的变成列表</span></span><br><span class="line"></span><br><span class="line">root_dir = <span class="string">"dataset/train"</span></span><br><span class="line">label_dir = <span class="string">"ants"</span></span><br><span class="line">path = os.path.join(root_dir,label_dir) <span class="comment"># 系统自动加起来，不会出错</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyData</span><span class="params">(Dataset)</span>:</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, root_dir, label_dir)</span>:</span></span><br><span class="line">self.root_dir = root_dir</span><br><span class="line">self.label_dir = label_dir</span><br><span class="line">self.path = os.path.join(self.root_dir,self.label_dir)</span><br><span class="line">self.img_path = os.listdir(self.path) <span class="comment"># 所有图片的名称</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self,idx)</span>:</span></span><br><span class="line">img_name = self.img_path[idx] <span class="comment"># 图片名</span></span><br><span class="line">img_item_path = os.path.join(self.root_dir,self.label_dir, img_name) <span class="comment"># 图片相对路径地址</span></span><br><span class="line">img = Image.open(img_item_path) <span class="comment"># 读取图片</span></span><br><span class="line">label = self.label_dir <span class="comment"># 这里label就是文件名</span></span><br><span class="line"><span class="keyword">return</span> img, label</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line"><span class="keyword">return</span> len(self.img_path) <span class="comment"># 数据集的长度</span></span><br><span class="line"></span><br><span class="line">root_dir = <span class="string">"dataset/train"</span></span><br><span class="line">ants_label_dir = <span class="string">"ants"</span></span><br><span class="line">bees_label_dir = <span class="string">"bees"</span></span><br><span class="line">ants_dataset = MyData(root_dir, ants_label_dir)</span><br><span class="line">bees_dataset = MyData(root_dir, bees_label_dir)</span><br><span class="line"></span><br><span class="line">img, label = ants_dataset[<span class="number">0</span>] <span class="comment"># 就自动调用了__getitem__获取了第一个</span></span><br><span class="line">img.show()</span><br><span class="line"></span><br><span class="line">train_dataset = ants_dataset + bees_dataset <span class="comment"># 合并数据集 数据增强</span></span><br></pre></td></tr></table></figure><h2><span id="gou-jian-zi-ji-de-wang-luo">构建自己的网络</span><a href="#gou-jian-zi-ji-de-wang-luo" class="header-anchor">#</a></h2><ol><li>处理数据</li><li>定义网络</li><li>定义损失函数</li><li>定义优化方法</li><li>训练</li></ol><p><strong>一个例子</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, D_in, H, D_out)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        在构造函数中，我们实例化了两个nn.Linear模块，并将它们作为成员变量。</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super(TwoLayerNet, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(D_in, H)</span><br><span class="line">        self.linear2 = torch.nn.Linear(H, D_out)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        在前向传播的函数中，我们接收一个输入的张量，也必须返回一个输出张量。</span></span><br><span class="line"><span class="string">        我们可以使用构造函数中定义的模块以及张量上的任意的（可微分的）操作。</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        h_relu = self.linear1(x).clamp(min=<span class="number">0</span>)</span><br><span class="line">        y_pred = self.linear2(h_relu)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line"><span class="comment"># N是批大小； D_in 是输入维度；</span></span><br><span class="line"><span class="comment"># H 是隐藏层维度； D_out 是输出维度</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 产生输入和输出的随机张量</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过实例化上面定义的类来构建我们的模型。</span></span><br><span class="line">model = TwoLayerNet(D_in, H, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造损失函数和优化器。</span></span><br><span class="line"><span class="comment"># SGD构造函数中对model.parameters()的调用，</span></span><br><span class="line"><span class="comment"># 将包含模型的一部分，即两个nn.Linear模块的可学习参数。</span></span><br><span class="line">loss_fn = torch.nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1e-4</span>)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># 前向传播：通过向模型传递x计算预测值y</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#计算并输出loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y)</span><br><span class="line">    <span class="comment"># print(t, loss.item())</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 清零梯度，反向传播，更新权重</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure></p><p>一个可以效仿的测试函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(model, device, test_loader)</span>:</span></span><br><span class="line">    model.eval()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> i,data <span class="keyword">in</span> enumerate(test_loader):          </span><br><span class="line">            x,y= data</span><br><span class="line">            x=x.to(device)</span><br><span class="line">            y=y.to(device)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            y_hat = model(x)</span><br><span class="line">            test_loss += criterion(y_hat, y).item() <span class="comment"># sum up batch loss</span></span><br><span class="line">            pred = y_hat.max(<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">1</span>] <span class="comment"># get the index of the max log-probability</span></span><br><span class="line">            correct += pred.eq(y.view_as(pred)).sum().item()</span><br><span class="line">    test_loss /= len(test_loader.dataset)</span><br><span class="line">    print(<span class="string">'\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n'</span>.format(</span><br><span class="line">        test_loss, correct, len(val_dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / len(val_dataset)))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;pytorch及其应用&quot;&gt;&lt;a href=&quot;#pytorch及其应用&quot; class=&quot;headerlink&quot; title=&quot;pytorch及其应用&quot;&gt;&lt;/a&gt;pytorch及其应用&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;支持GPU、灵活；&lt;/li&gt;
&lt;li&gt;支持动态神经网络；&lt;/li&gt;
&lt;li&gt;底层代码易于理解；&lt;/li&gt;
&lt;li&gt;命令式体验；自定义扩展&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;对比TensorFlow，全面性不足，不支持快速傅里叶、沿维翻转张量和检查无穷与非数值张量；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;针对移动端、嵌入式部署以及高性能服务器端的部署其性能表现有待提升；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;因为框架较新，社区没有那么强大，在文档方面其C库大多数没有文档。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;
    
    </summary>
    
    
    
      <category term="随笔" scheme="https://sunxiaojie99.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>A View of Cloud Computing</title>
    <link href="https://sunxiaojie99.github.io/2020/04/20/cloud-compute/"/>
    <id>https://sunxiaojie99.github.io/2020/04/20/cloud-compute/</id>
    <published>2020-04-20T03:28:52.000Z</published>
    <updated>2020-06-07T04:11:52.521Z</updated>
    
    <content type="html"><![CDATA[<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="This article is not open to you">    <label for="pass">This article is not open to you</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      Welcome to my blog, this is a paper note, which needs password to access.
    
    </summary>
    
    
    
      <category term="paper" scheme="https://sunxiaojie99.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>build a wonderful world</title>
    <link href="https://sunxiaojie99.github.io/2020/04/18/world/"/>
    <id>https://sunxiaojie99.github.io/2020/04/18/world/</id>
    <published>2020-04-18T06:31:42.000Z</published>
    <updated>2020-04-20T07:42:24.499Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="ke-xue-ji-zhu-dao-di-ke-yi-wei-wo-men-dai-lai-shi-me">科学技术到底可以为我们带来什么</span><a href="#ke-xue-ji-zhu-dao-di-ke-yi-wei-wo-men-dai-lai-shi-me" class="header-anchor">#</a></h1><p>这是本篇文章的主题：社会企业家朱莉·科杜瓦（Julie Cordua）致力于解决一个“难以启齿”的问题：互联网上以图片和视频形式存在的儿童性侵。</p><h3><span id="chi-wo-hen-yuan-ba">离我很远吧</span><a href="#chi-wo-hen-yuan-ba" class="header-anchor">#</a></h3><p>Ted talk video的开始，首先映入眼帘的就是纯白色的背景，大大的字写着，“涉及成人话题”，在高科技术快速发达的今天，我们所有人无一不在享受着互联网技术带来的便利，最近出现的“星星”事件，我大胆猜测，虽然引起了人们的注意，但恐怕大多数人也只是和最开始的我抱着相同的心理，“竟然有这样的人”，“要制裁他”，但每个人心中也都有想，“这应该离我很远吧”。</p><a id="more"></a><h3><span id="nei-rong-ji-huo-bi">内容即货币</span><a href="#nei-rong-ji-huo-bi" class="header-anchor">#</a></h3><p>video中谈到，在刚刚过去的2019年，仅在美国，就仅在美国就有超过4500万涉及儿童性侵的图像和视频内容被举报至国家失踪与受虐儿童中心，比2018年翻了翻。更是难以想象这些数字背后的细节真相： 超过60%的图像拍摄的是不到12岁的孩子， 而且大多包含极端性暴力行为。 虐待者在专门讨论虐待儿童的聊天室里颇受欢迎， 随着更强的侵犯和更多受害者的出现， 他们在那里的排名和地位就更高。 </p><p>有一句话说的很对，它们的世界中，内容就是货币。它们快速掌握日渐更新的新技术，不断的加害于还没有认识清这个世界的孩子。 我们作为一个社会整体的回应却严重滞后。那些施暴者不分国界，甚至不分性别，在全世界各大品台中流动，而我们的执法工作仅在一个司法管辖区进行， 每一个企业只专注于他们自己的平台， 无利益即无关的想法使得他们之间很少沟通。</p><h3><span id="suo-en-de-xing-dong">索恩的行动</span><a href="#suo-en-de-xing-dong" class="header-anchor">#</a></h3><p>在索恩（Thorn）公司，她们的行动分为两步，联系执法机构政府，以更快的帮助孩子被解救；同时联系各大视频网站，通过使用她们的软件检测哪些涉及儿童性侵的图像和视频，报告给执法机构。</p><p>她们使用的技术是获取已经发现的在互联网传播的受害者视频，获得哈希值，利用哈希值唯一性，去检索各大网站的数据库，如果比对发现哈希值相同，移除内容， 并且将其报告给国家失踪与受虐儿童中心， 然后那些哈希再返回到她们的系统， 令每个使用该软件的企业都可以有更多的哈希值以比较。 当数百万的哈希值指向更多内容时， 全世界的企业就能实时识别并移除数百万的内容， 从全球的网络上移除儿童性侵媒体内容的速度将会大大提升。</p><p>例如，她们第一个合作伙伴，Imgur，每天有用户生产 的数百万内容被上传， 在开始使用系统的20分钟内， 有人尝试上传一个已知的儿童性侵内容。 Imgur因此能够及时阻止，移除内容， 并向国家失踪与受虐儿童中心报告。 他们更进一步， 找到并审查了内容发布人的账号， 却发现了其他上百个没看过的儿童性侵媒体内容。</p><h3><span id="together">Together</span><a href="#together" class="header-anchor">#</a></h3><p>很明显，如果需要构建这样的系统，必须拥有足够多的视频哈希值，不断扩充数据库，来更有效的组织视频的传播和散布。这也是这次ted演讲的目的，动员世界范围内数千名警官， 以及数百家企业。 </p><p>第一代受到侵犯的媒体资料被大肆传播的孩子们已经长大成人。加拿大儿童保护中心最近针对这些年轻人做了一个研究， 80%有过自杀的想法， 超过60%曾尝试自杀。 他们的大部分人每天都生活在恐惧中： 当他们走上街头， 或参加一个面试， 或是去学校， 或是在网上碰见的某个人，有超过30%人， 噩梦成为现实， 他们因为网上性侵的内容被认出。</p><p><strong>这条路不简单， 但并不是不可能</strong>。 现在需要展现我们社会的决心， 去着手解决非常难以直面的问题， 在黑暗中创造希望， 让那些孩子的声音能被听见； 去展现企业们的决心，采取一切措施并确保他们的平台不与儿童侵犯者共谋； 去展现政府部门的决心， 投资执法部门破案设施， 来调查数字先行的犯罪， 即便受害者无法为自己申辩。 </p><blockquote><p>作为一名有机会帮助到打击数字先行犯罪的人，希望未来我的研究可以做些什么，可以不仅仅是靠一个个的哈希值的比对，人为的加入数据库。</p></blockquote><h3><span id="in-a-future-every-child-can-simply-be-a-kid">In a future，every child can simply be a kid</span><a href="#in-a-future-every-child-can-simply-be-a-kid" class="header-anchor">#</a></h3><p><img src="/2020/04/18/world/a.png" alt="a"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;科学技术到底可以为我们带来什么&quot;&gt;&lt;a href=&quot;#科学技术到底可以为我们带来什么&quot; class=&quot;headerlink&quot; title=&quot;科学技术到底可以为我们带来什么&quot;&gt;&lt;/a&gt;科学技术到底可以为我们带来什么&lt;/h1&gt;&lt;p&gt;这是本篇文章的主题：社会企业家朱莉·科杜瓦（Julie Cordua）致力于解决一个“难以启齿”的问题：互联网上以图片和视频形式存在的儿童性侵。&lt;/p&gt;
&lt;h3 id=&quot;离我很远吧&quot;&gt;&lt;a href=&quot;#离我很远吧&quot; class=&quot;headerlink&quot; title=&quot;离我很远吧&quot;&gt;&lt;/a&gt;离我很远吧&lt;/h3&gt;&lt;p&gt;Ted talk video的开始，首先映入眼帘的就是纯白色的背景，大大的字写着，“涉及成人话题”，在高科技术快速发达的今天，我们所有人无一不在享受着互联网技术带来的便利，最近出现的“星星”事件，我大胆猜测，虽然引起了人们的注意，但恐怕大多数人也只是和最开始的我抱着相同的心理，“竟然有这样的人”，“要制裁他”，但每个人心中也都有想，“这应该离我很远吧”。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="随笔" scheme="https://sunxiaojie99.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>Attribute-aware Pedestrian Image Editing</title>
    <link href="https://sunxiaojie99.github.io/2020/04/16/APIE/"/>
    <id>https://sunxiaojie99.github.io/2020/04/16/APIE/</id>
    <published>2020-04-16T03:28:52.000Z</published>
    <updated>2020-04-17T13:12:34.877Z</updated>
    
    <content type="html"><![CDATA[<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="This article is not open to you">    <label for="pass">This article is not open to you</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      Welcome to my blog, this is a paper note, which needs password to access.
    
    </summary>
    
    
    
      <category term="paper" scheme="https://sunxiaojie99.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>how to use markdown</title>
    <link href="https://sunxiaojie99.github.io/2020/04/13/markdown/"/>
    <id>https://sunxiaojie99.github.io/2020/04/13/markdown/</id>
    <published>2020-04-13T06:51:10.000Z</published>
    <updated>2020-04-17T12:32:02.886Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="1-biao-ti">1 标题</span><a href="#1-biao-ti" class="header-anchor">#</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 一级标题</span><br><span class="line">## 二级标题</span><br><span class="line">### 三级标题</span><br><span class="line">#### 四级标题</span><br><span class="line">##### 五级标题</span><br><span class="line">###### 六级标题</span><br></pre></td></tr></table></figure><a id="more"></a><h2><span id="2-duan-luo">2 段落</span><a href="#2-duan-luo" class="header-anchor">#</a></h2><blockquote><p>段落的换行是使用<strong>两个以上空格加上回车</strong>，也可以在段落后面使用一个空行来表示重新开始一个段落</p></blockquote><p><strong>字体</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">*斜体文本*</span><br><span class="line">**粗体文本**</span><br><span class="line">***粗斜体文本***</span><br></pre></td></tr></table></figure><p><strong>分割线</strong></p><blockquote><p>在一行中用三个以上的星号建立一个分隔线</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">***</span><br></pre></td></tr></table></figure><p><strong>删除线</strong></p><p><del>在两端加上两个波浪线</del></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~~Baidu~~</span><br></pre></td></tr></table></figure><p><strong>下划线</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;u&gt;带下划线的文本&lt;&#x2F;u&gt;</span><br></pre></td></tr></table></figure><p><strong>脚注</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">创建脚注格式类似这样 [^RUNOOB]。</span><br><span class="line">[^RUNOOB]:菜鸟教程 -- 学的不仅是技术，更是梦想！！！</span><br></pre></td></tr></table></figure><p>我是一个脚注  <sup><a href="#fn_myself" id="reffn_myself">myself</a></sup> 。</p><h2><span id="3-lie-biao">3 列表</span><a href="#3-lie-biao" class="header-anchor">#</a></h2><p><strong>无序列表</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 第一项</span><br><span class="line">- 第二项</span><br><span class="line">- 第三项</span><br></pre></td></tr></table></figure><p><strong>有序列表</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 第一项</span><br><span class="line">2. 第二项</span><br><span class="line">3. 第三项</span><br></pre></td></tr></table></figure><p><strong>列表嵌套</strong></p><blockquote><p>只需在子列表中的选项添加四个空格即可</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1. 第一项：</span><br><span class="line">    - 第一项嵌套的第一个元素</span><br><span class="line">    - 第一项嵌套的第二个元素</span><br><span class="line">2. 第二项：</span><br><span class="line">    - 第二项嵌套的第一个元素</span><br><span class="line">    - 第二项嵌套的第二个元素</span><br></pre></td></tr></table></figure><h2><span id="4-qu-kuai">4 区块</span><a href="#4-qu-kuai" class="header-anchor">#</a></h2><blockquote><p>在段落开头使用 &gt; 符号 ，然后后面紧跟一个<strong>空格</strong>符号：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">区块嵌套</span><br><span class="line">&gt; 最外层</span><br><span class="line">&gt; &gt; 第一层嵌套</span><br><span class="line">&gt; &gt; &gt; 第二层嵌套</span><br><span class="line"></span><br><span class="line">区块中使用列表</span><br><span class="line">&gt; 1. 第一项</span><br><span class="line">&gt; 2. 第二项</span><br><span class="line">&gt; + 第一项</span><br><span class="line">&gt; + 第二项</span><br><span class="line">&gt; + 第三项</span><br><span class="line"></span><br><span class="line">列表中使用区块：需要在 &gt; 前添加四个空格的缩进</span><br><span class="line">* 第一项</span><br><span class="line">    &gt; oneone</span><br><span class="line">    &gt; twotwo</span><br><span class="line">* 第二项</span><br></pre></td></tr></table></figure><ul><li>第一项<blockquote><p>oneone<br>twotwo</p></blockquote></li></ul><h2><span id="5-dai-ma">5 代码</span><a href="#5-dai-ma" class="header-anchor">#</a></h2><blockquote><p>用 ``` 包裹一段代码，并指定一种语言（也可以不指定）</p></blockquote><h2><span id="6-lian-jie">6 链接</span><a href="#6-lian-jie" class="header-anchor">#</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">这是一个链接 [链接名](https:&#x2F;&#x2F;www.baidu.com)</span><br><span class="line"></span><br><span class="line">直接使用链接地址</span><br><span class="line">&lt;https:&#x2F;&#x2F;www.baidu.com&gt;</span><br><span class="line"></span><br><span class="line">可以通过变量来设置一个链接，变量赋值在文档末尾进行：</span><br><span class="line">这个链接用 1 作为网址变量 [Google][1]</span><br><span class="line">这个链接用 runoob 作为网址变量 [Runoob][runoob]</span><br><span class="line">然后在文档的结尾为变量赋值（网址）</span><br><span class="line"></span><br><span class="line">[1]: http:&#x2F;&#x2F;www.google.com&#x2F;</span><br><span class="line">[runoob]: http:&#x2F;&#x2F;www.runoob.com&#x2F;</span><br></pre></td></tr></table></figure><p>这是一个链接 <a href="https://www.baidu.com" target="_blank" rel="noopener">链接名</a></p><h2><span id="7-tu-pian">7 图片</span><a href="#7-tu-pian" class="header-anchor">#</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">开头一个感叹号 !;接着一个方括号，里面放上图片的替代文字;接着一个普通括号，里面放上图片的网址</span><br><span class="line">![alt 属性文本](图片地址)</span><br><span class="line"></span><br><span class="line">Markdown 还没有办法指定图片的高度与宽度，如果你需要的话，你可以使用普通的 &lt;img&gt; 标签。</span><br><span class="line">&lt;img src&#x3D;&quot;xxxx.png&quot; width&#x3D;&quot;50%&quot;&gt;</span><br></pre></td></tr></table></figure><h2><span id="8-biao-ge">8 表格</span><a href="#8-biao-ge" class="header-anchor">#</a></h2><blockquote><p>使用 | 来分隔不同的单元格，使用 - 来分隔表头和其他行<br>并且可以设置表格的对齐方式</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">| 表头 | 表头 |</span><br><span class="line">| --- | --- |</span><br><span class="line">| 单元格 | 单元格 |</span><br><span class="line">| 单元格 | 单元格 |</span><br><span class="line"></span><br><span class="line">-: 设置内容和标题栏居右对齐。</span><br><span class="line">:- 设置内容和标题栏居左对齐。</span><br><span class="line">:-: 设置内容和标题栏居中对齐</span><br><span class="line"></span><br><span class="line">| 左对齐 | 右对齐 | 居中对齐 |</span><br><span class="line">| :-----| ----: | :----: |</span><br><span class="line">| 单元格 | 单元格 | 单元格 |</span><br><span class="line">| 单元格 | 单元格 | 单元格 |</span><br></pre></td></tr></table></figure><h2><span id="9-html">9 HTML</span><a href="#9-html" class="header-anchor">#</a></h2><blockquote><p>Markdown 涵盖范围之内的标签，都可以直接在文档里面用 HTML 撰写<br>持的 HTML 元素有：<kbd> <b> <i> <em> <sup> <sub> <br>等 ，如：</sub></sup></em></i></b></kbd></p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">使用 &lt;kbd&gt;Ctrl&lt;&#x2F;kbd&gt;+&lt;kbd&gt;Alt&lt;&#x2F;kbd&gt;+&lt;kbd&gt;Del&lt;&#x2F;kbd&gt; 重启电脑</span><br></pre></td></tr></table></figure><p>使用 <kbd>Ctrl</kbd>+<kbd>Alt</kbd>+<kbd>Del</kbd> 重启电脑</p><h2><span id="10-gong-shi">10 公式</span><a href="#10-gong-shi" class="header-anchor">#</a></h2><blockquote><p>使用两个美元符 $$ 包裹 TeX 或 LaTeX 格式的数学公式来实现</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$$</span><br><span class="line">\mathbf&#123;V&#125;_1 \times \mathbf&#123;V&#125;_2 &#x3D;  \begin&#123;vmatrix&#125; </span><br><span class="line">\mathbf&#123;i&#125; &amp; \mathbf&#123;j&#125; &amp; \mathbf&#123;k&#125; \\</span><br><span class="line">\frac&#123;\partial X&#125;&#123;\partial u&#125; &amp;  \frac&#123;\partial Y&#125;&#123;\partial u&#125; &amp; 0 \\</span><br><span class="line">\frac&#123;\partial X&#125;&#123;\partial v&#125; &amp;  \frac&#123;\partial Y&#125;&#123;\partial v&#125; &amp; 0 \\</span><br><span class="line">\end&#123;vmatrix&#125;</span><br><span class="line">$&#123;$tep1&#125;&#123;\style&#123;visibility:hidden&#125;&#123;(x+1)(x+1)&#125;&#125;</span><br><span class="line">$$</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\mathbf{V}_1 \times \mathbf{V}_2 =  \begin{vmatrix} \mathbf{i} & \mathbf{j} & \mathbf{k} \\\frac{\partial X}{\partial u} &  \frac{\partial Y}{\partial u} & 0 \\\frac{\partial X}{\partial v} &  \frac{\partial Y}{\partial v} & 0 \\\end{vmatrix}${$tep1}{\style{visibility:hidden}{(x+1)(x+1)}}</script><h2><span id="11-liu-cheng-tu">11 流程图</span><a href="#11-liu-cheng-tu" class="header-anchor">#</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">横向流程图</span><br><span class="line"> + mermaid</span><br><span class="line">graph LR</span><br><span class="line">A[方形] --&gt; B(圆角)</span><br><span class="line">B--&gt; C&#123;条件a&#125;</span><br><span class="line">C--&gt;|a&#x3D;1| D[结果1]</span><br><span class="line">C--&gt;|a&#x3D;2| E[结果2]</span><br><span class="line">F[横向流程图]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">A[方形] --&gt; B(圆角)</span><br><span class="line">B--&gt; C&#123;条件a&#125;</span><br><span class="line">C--&gt;|a&#x3D;1| D[结果1]</span><br><span class="line">C--&gt;|a&#x3D;2| E[结果2]</span><br><span class="line">F[横向流程图]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">竖向流程图</span><br><span class="line">graph TD</span><br><span class="line">A[方形] --&gt; B(圆角)</span><br><span class="line">B --&gt; C&#123;条件a&#125;</span><br><span class="line">C --&gt; |a&#x3D;1| D[结果1]</span><br><span class="line">C --&gt; |a&#x3D;2| E[结果2]</span><br><span class="line">F[竖向流程图]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">A[方形] --&gt; B(圆角)</span><br><span class="line">    B --&gt; C&#123;条件a&#125;</span><br><span class="line">    C --&gt; |a&#x3D;1| D[结果1]</span><br><span class="line">    C --&gt; |a&#x3D;2| E[结果2]</span><br><span class="line">    F[竖向流程图]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      未完待续，持续更新
    
    </summary>
    
    
    
      <category term="随笔" scheme="https://sunxiaojie99.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>The Website</title>
    <link href="https://sunxiaojie99.github.io/2020/04/13/About%20Me/"/>
    <id>https://sunxiaojie99.github.io/2020/04/13/About%20Me/</id>
    <published>2020-04-13T04:34:02.000Z</published>
    <updated>2020-04-20T07:42:32.071Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="jie-shao">介绍</span><a href="#jie-shao" class="header-anchor">#</a></h1><p>本网站用途：</p><ol><li>随时记录一些个人的学习总结；</li><li>记录一些关于日常生活的感悟；</li><li>其他一些杂七杂八的东西；</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;jie-shao&quot;&gt;介绍&lt;/span&gt;&lt;a href=&quot;#jie-shao&quot; class=&quot;header-anchor&quot;&gt;#&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本网站用途：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;随时记录一些个人的学习总结；&lt;/li&gt;
&lt;li&gt;记录一些关于日常
      
    
    </summary>
    
    
    
      <category term="other" scheme="https://sunxiaojie99.github.io/tags/other/"/>
    
  </entry>
  
</feed>
